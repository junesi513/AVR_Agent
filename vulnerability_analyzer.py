#!/usr/bin/env python3
"""
ì·¨ì•½ì  ë¶„ì„ ë° ìˆ˜ì • Agent
Author: Assistant
Description: Java ì†ŒìŠ¤ì½”ë“œì˜ ì·¨ì•½ì ì„ ë¶„ì„í•˜ê³  íŒ¨ì¹˜ë¥¼ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import os
import sys
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from abc import ABC, abstractmethod
from llm_interfaces import LLMFactory, LLMInterface

# ë¡œê¹… ì„¤ì •
def setup_logging():
    log_dir = Path("./log")
    log_dir.mkdir(exist_ok=True)
    
    log_file = log_dir / f"vulnerability_analyzer_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

class VulnerabilityAnalyzer:
    """ë©”ì¸ ì·¨ì•½ì  ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self, vuln_id: int = 1, llm_config: Optional[Dict[str, Any]] = None):
        self.vuln_id = vuln_id
        self.logger = setup_logging()
        self.source_path = Path(f"./benchmark/Java/VUL4J/VUL4J-{vuln_id}")
        self.target_path = self.source_path  # ì •ì  ë¶„ì„ ëŒ€ìƒ ê²½ë¡œ
        self.rule_dir = Path(f"./rule/VUL4J-{vuln_id}")
        self.log_dir = Path(f"./log/VUL4J-{vuln_id}")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.rule_dir.mkdir(parents=True, exist_ok=True)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # LLM ì„¤ì • ë¡œë“œ
        self.llm_config = self._load_llm_config(llm_config)
        self.llm = self._initialize_llm()
        
        # ë‹¨ê³„ë³„ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        self.ast_processor = ASTProcessor()
        self.vulnerability_detector = VulnerabilityDetector(self.llm)
        self.patch_generator = PatchGenerator(self.llm)
        
        self.logger.info(f"ì·¨ì•½ì  ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ - ID: {vuln_id}")
        if self.llm:
            self.logger.info(f"LLM ì—°ê²°ë¨: {self.llm.__class__.__name__}")
    
    def _load_llm_config(self, llm_config: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """LLM ì„¤ì • ë¡œë“œ"""
        if llm_config:
            return llm_config
        
        # llm_config.json íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ
        config_file = Path("llm_config.json")
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                # í™œì„±í™”ëœ LLM ì°¾ê¸°
                for llm_cfg in config_data.get("llm_configs", []):
                    if llm_cfg.get("enabled", False):
                        return llm_cfg
                
                # ê¸°ë³¸ LLM ì‚¬ìš©
                default_llm_name = config_data.get("default_llm", "qwen")
                for llm_cfg in config_data.get("llm_configs", []):
                    if llm_cfg.get("name") == default_llm_name:
                        return llm_cfg
                        
            except Exception as e:
                self.logger.warning(f"LLM ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        # ê¸°ë³¸ ì„¤ì • ë°˜í™˜ (Ollama/Qwen)
        return {
            "type": "ollama",
            "model": "qwen:7b", 
            "base_url": "http://localhost:11434",
            "temperature": 0.1
        }
    
    def _initialize_llm(self) -> Optional[LLMInterface]:
        """LLM ì´ˆê¸°í™”"""
        try:
            llm_type = self.llm_config.get("type", "ollama")
            return LLMFactory.create_llm(llm_type, **self.llm_config)
        except Exception as e:
            self.logger.warning(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.logger.info("íŒ¨í„´ ë§¤ì¹­ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´")
            return None
    
    def analyze(self) -> Dict[str, Any]:
        """ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        try:
            self.logger.info("=== Stage 1: ì‚¬ì „ ì‘ì—… ì‹œì‘ ===")
            ast_data = self.stage1_preprocessing()
            
            self.logger.info("=== Stage 2: ì·¨ì•½ì  ë¶„ì„ ì‹œì‘ ===")
            vulnerabilities = self.stage2_vulnerability_analysis(ast_data)
            
            self.logger.info("=== Stage 3: íŒ¨ì¹˜ ìƒì„± ì‹œì‘ ===")
            patches = self.stage3_patch_generation(vulnerabilities)
            
            result = {
                "vuln_id": self.vuln_id,
                "timestamp": datetime.now().isoformat(),
                "ast_data": ast_data,
                "vulnerabilities": vulnerabilities,
                "patches": patches,
                "status": "completed"
            }
            
            # ê²°ê³¼ ì €ì¥
            self._save_analysis_result(result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def stage1_preprocessing(self) -> Dict[str, Any]:
        """Stage 1: AST ë…¸ë“œ ì¶”ì¶œ ë° í•¨ìˆ˜/í´ë˜ìŠ¤ ë‹¨ìœ„ ë¶„ë¦¬"""
        self.logger.info("AST ë…¸ë“œ ì¶”ì¶œ ì‹œì‘")
        
        java_files = list(self.source_path.glob("*.java"))
        if not java_files:
            raise FileNotFoundError(f"Java íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.source_path}")
        
        ast_data = {}
        for java_file in java_files:
            self.logger.info(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘: {java_file.name}")
            file_ast = self.ast_processor.extract_ast(java_file)
            ast_data[java_file.name] = file_ast
        
        self.logger.info(f"AST ì¶”ì¶œ ì™„ë£Œ - {len(ast_data)} íŒŒì¼ ì²˜ë¦¬")
        return ast_data
    
    def stage2_vulnerability_analysis(self, ast_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Stage 2: ì·¨ì•½ì  ë¶„ì„"""
        vulnerabilities = []
        
        for file_name, file_ast in ast_data.items():
            self.logger.info(f"ì·¨ì•½ì  ë¶„ì„ ì¤‘: {file_name}")
            
            # ê° í•¨ìˆ˜ì— ëŒ€í•´ ì·¨ì•½ì  ë¶„ì„
            for func_info in file_ast.get("functions", []):
                func_name = func_info["name"]
                
                # LLM ì·¨ì•½ì  ê°€ì„¤ ìƒì„±
                hypothesis = self.vulnerability_detector.generate_hypothesis(func_info)
                
                if hypothesis:
                    # Semgrep ë° CodeQL ê·œì¹™ ìƒì„±
                    semgrep_rule = self.vulnerability_detector.generate_semgrep_rule(
                        self.vuln_id, func_name, hypothesis
                    )
                    codeql_rule = self.vulnerability_detector.generate_codeql_rule(
                        self.vuln_id, func_name, hypothesis
                    )
                    
                    # ê·œì¹™ ì €ì¥
                    semgrep_rule_file = self._save_rule("semgrep", self.vuln_id, func_name, semgrep_rule)
                    codeql_rule_file = self._save_rule("codeql", self.vuln_id, func_name, codeql_rule)
                    
                    # ì‹¤ì œ ì •ì  ë¶„ì„ ë„êµ¬ ì‹¤í–‰
                    semgrep_results = None
                    codeql_results = None
                    
                    if semgrep_rule_file and semgrep_rule.strip():
                        self.logger.info(f"Semgrep ì‹¤í–‰ ì¤‘: {func_name}")
                        semgrep_results = self.vulnerability_detector.run_semgrep_analysis(
                            str(semgrep_rule_file), 
                            str(self.target_path)
                        )
                    
                    if codeql_rule_file and codeql_rule.strip():
                        self.logger.info(f"CodeQL ì‹¤í–‰ ì¤‘: {func_name}")
                        codeql_results = self.vulnerability_detector.run_codeql_analysis(
                            str(codeql_rule_file),
                            str(self.target_path)
                        )
                    
                    confirmed = self._is_vulnerability_confirmed(semgrep_results, codeql_results)
                    
                    vulnerability = {
                        "file": file_name,
                        "function": func_name,
                        "hypothesis": hypothesis,
                        "semgrep_rule": semgrep_rule,
                        "codeql_rule": codeql_rule,
                        "severity": hypothesis.get("severity", "medium"),
                        "semgrep_results": semgrep_results,
                        "codeql_results": codeql_results,
                        "confirmed": confirmed
                    }
                    
                    # ê²€ì¦ëœ ì·¨ì•½ì ë§Œ ê²°ê³¼ì— í¬í•¨ (ê°œë°œ/í…ŒìŠ¤íŠ¸ì‹œì—ëŠ” ëª¨ë‘ í¬í•¨)
                    vulnerabilities.append(vulnerability)
        
        self.logger.info(f"ì·¨ì•½ì  ë¶„ì„ ì™„ë£Œ - {len(vulnerabilities)}ê°œ ë°œê²¬")
        return vulnerabilities
    
    def stage3_patch_generation(self, vulnerabilities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Stage 3: íŒ¨ì¹˜ ìƒì„±"""
        patches = []
        
        for vuln in vulnerabilities:
            self.logger.info(f"íŒ¨ì¹˜ ìƒì„± ì¤‘: {vuln['function']}")
            
            patch = self.patch_generator.generate_patch(vuln)
            if patch:
                patches.append(patch)
        
        self.logger.info(f"íŒ¨ì¹˜ ìƒì„± ì™„ë£Œ - {len(patches)}ê°œ ìƒì„±")
        return patches
    
    def _save_rule(self, rule_type: str, vuln_id: int, func_name: str, rule_content: str):
        """ê·œì¹™ íŒŒì¼ ì €ì¥"""
        if not rule_content.strip():
            return None
        
        # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        self.rule_dir.mkdir(parents=True, exist_ok=True)
            
        rule_file = self.rule_dir / f"{rule_type}{vuln_id}-{func_name}"
        with open(rule_file, 'w', encoding='utf-8') as f:
            f.write(rule_content)
        self.logger.info(f"ê·œì¹™ ì €ì¥ë¨: {rule_file}")
        return rule_file
    
    def _is_vulnerability_confirmed(self, semgrep_results: Dict[str, Any], codeql_results: Dict[str, Any]) -> bool:
        """ì •ì  ë¶„ì„ ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì·¨ì•½ì  í™•ì¸"""
        confirmed = False
        confidence_score = 0.0
        
        # Semgrep ê²°ê³¼ í™•ì¸
        if semgrep_results and semgrep_results.get("status") == "success":
            findings = semgrep_results.get("findings", [])
            if findings:
                confirmed = True
                confidence_score += 0.6  # Semgrep ê²€ì¦ì‹œ 60% ì‹ ë¢°ë„
                self.logger.info(f"Semgrep ê²€ì¦ ì„±ê³µ: {len(findings)}ê°œ ë°œê²¬")
        
        # CodeQL ê²°ê³¼ í™•ì¸  
        if codeql_results and codeql_results.get("status") == "success":
            findings = codeql_results.get("findings", [])
            if findings and len(findings) > 1:  # CSV í—¤ë” ì œì™¸
                confirmed = True
                confidence_score += 0.4  # CodeQL ê²€ì¦ì‹œ 40% ì‹ ë¢°ë„
                self.logger.info(f"CodeQL ê²€ì¦ ì„±ê³µ: {len(findings)-1}ê°œ ë°œê²¬")
        
        # ê²€ì¦ ì‹¤íŒ¨ ë¡œê·¸
        if not confirmed:
            self.logger.warning("ì •ì  ë¶„ì„ ë„êµ¬ ê²€ì¦ ì‹¤íŒ¨ - ì·¨ì•½ì  ë¯¸í™•ì¸")
            
        return confirmed
    
    def _save_analysis_result(self, result: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        result_file = self.log_dir / f"analysis_result_{self.vuln_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        self.logger.info(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ë¨: {result_file}")


class ASTProcessor:
    """AST ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def extract_ast(self, java_file: Path) -> Dict[str, Any]:
        """Java íŒŒì¼ì—ì„œ AST ì¶”ì¶œ ë° í•¨ìˆ˜/í´ë˜ìŠ¤ ë¶„ë¦¬"""
        with open(java_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ê°„ë‹¨í•œ Java íŒŒì‹± (ì‹¤ì œë¡œëŠ” JavaParser ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ)
        ast_data = {
            "file_path": str(java_file),
            "content": content,
            "classes": self._extract_classes(content),
            "functions": self._extract_methods(content),
            "imports": self._extract_imports(content)
        }
        
        return ast_data
    
    def _extract_classes(self, content: str) -> List[Dict[str, Any]]:
        """í´ë˜ìŠ¤ ì •ë³´ ì¶”ì¶œ"""
        classes = []
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            if stripped.startswith('public class ') or stripped.startswith('class '):
                class_name = stripped.split()[2] if 'public' in stripped else stripped.split()[1]
                if '{' in class_name:
                    class_name = class_name.split('{')[0]
                
                classes.append({
                    "name": class_name,
                    "line": i + 1,
                    "modifiers": ["public"] if "public" in stripped else [],
                    "interfaces": self._extract_implements(stripped)
                })
        
        return classes
    
    def _extract_methods(self, content: str) -> List[Dict[str, Any]]:
        """ë©”ì†Œë“œ ì •ë³´ ì¶”ì¶œ (ì‹¤ì œ êµ¬í˜„ ì½”ë“œ í¬í•¨)"""
        methods = []
        lines = content.split('\n')
        
        i = 0
        while i < len(lines):
            stripped = lines[i].strip()
            
            # ì–´ë…¸í…Œì´ì…˜ ê±´ë„ˆë›°ê¸°
            if stripped.startswith('@'):
                i += 1
                continue
            
            # ë©”ì†Œë“œ ì‹œê·¸ë‹ˆì²˜ íŒ¨í„´ (ë” ì •í™•í•˜ê²Œ)
            is_method_line = (
                # ì ‘ê·¼ ì œí•œìë¡œ ì‹œì‘í•˜ëŠ” ë©”ì†Œë“œ
                (stripped.startswith('public ') or stripped.startswith('private ') or 
                 stripped.startswith('protected ') or stripped.startswith('static ')) and
                '(' in stripped and
                not stripped.strip().endswith(';') and  # ë©”ì†Œë“œ ì„ ì–¸ì´ ì•„ë‹Œ ì •ì˜
                not '=' in stripped.split('(')[0] and  # ëŒ€ì…ë¬¸ì´ ì•„ë‹˜
                not stripped.startswith('if ') and     # ifë¬¸ì´ ì•„ë‹˜
                not stripped.startswith('for ') and    # forë¬¸ì´ ì•„ë‹˜
                not stripped.startswith('while ') and  # whileë¬¸ì´ ì•„ë‹˜
                not '.' in stripped.split('(')[0].split()[-1] and  # ë©”ì†Œë“œ í˜¸ì¶œì´ ì•„ë‹˜
                not 'new ' in stripped  # ìƒì„±ì í˜¸ì¶œì´ ì•„ë‹˜
            )
            
            if is_method_line:
                # ë©”ì†Œë“œ ì‹œê·¸ë‹ˆì²˜ì™€ ë³¸ë¬¸ì„ ë¶„ë¦¬í•´ì„œ ì²˜ë¦¬
                signature_lines = [stripped]
                j = i + 1
                
                # ì‹œê·¸ë‹ˆì²˜ ì™„ì„±ê¹Œì§€ ìˆ˜ì§‘ ('{' ë˜ëŠ” 'throws' ì „ê¹Œì§€)
                while j < len(lines):
                    next_line = lines[j].strip()
                    if '{' in next_line:
                        # throwsê°€ ìˆìœ¼ë©´ í¬í•¨
                        if 'throws' in next_line.split('{')[0]:
                            signature_lines.append(next_line.split('{')[0].strip())
                        break
                    elif 'throws' in next_line:
                        signature_lines.append(next_line)
                        j += 1
                        continue
                    elif next_line and not next_line.startswith('//'):
                        signature_lines.append(next_line)
                    j += 1
                
                # ì‹œê·¸ë‹ˆì²˜ ì •ë¦¬
                method_signature = ' '.join(signature_lines).strip()
                
                # ë©”ì†Œë“œ ë³¸ë¬¸ ì¶”ì¶œ (j ìœ„ì¹˜ë¶€í„°)
                method_body = self._extract_method_body(lines, j)
                
                method_info = self._parse_method_signature(method_signature)
                if method_info and method_info.get("name"):
                    method_info["line"] = i + 1
                    method_info["body_start"] = j + 1
                    method_info["full_signature"] = method_signature
                    method_info["implementation"] = method_body  # ì‹¤ì œ êµ¬í˜„ ì½”ë“œ ì¶”ê°€
                    methods.append(method_info)
            
            i += 1
        
        return methods
    
    def _extract_method_body(self, lines: List[str], start_index: int) -> str:
        """ë©”ì†Œë“œ ë³¸ë¬¸ ì¶”ì¶œ"""
        if start_index >= len(lines):
            return ""
        
        method_body_lines = []
        brace_count = 0
        started = False
        
        # start_indexë¶€í„° ì‹œì‘í•´ì„œ ì²« ë²ˆì§¸ { ì°¾ê¸°
        for i in range(start_index, len(lines)):
            line = lines[i]
            
            # ì²« ë²ˆì§¸ { ì°¾ê¸°
            if '{' in line and not started:
                started = True
                # { ì´í›„ ë¶€ë¶„ë¶€í„° ì‹œì‘
                brace_part = line[line.find('{'):]
                brace_count += brace_part.count('{')
                brace_count -= brace_part.count('}')
                method_body_lines.append(line)
                
                if brace_count == 0:  # ë©”ì†Œë“œ ë (í•œ ì¤„ ë©”ì†Œë“œ)
                    break
            elif started:
                brace_count += line.count('{')
                brace_count -= line.count('}')
                method_body_lines.append(line)
                
                if brace_count == 0:  # ë©”ì†Œë“œ ë
                    break
        
        return '\n'.join(method_body_lines)
    
    def _extract_imports(self, content: str) -> List[str]:
        """import ë¬¸ ì¶”ì¶œ"""
        imports = []
        for line in content.split('\n'):
            stripped = line.strip()
            if stripped.startswith('import ') and stripped.endswith(';'):
                imports.append(stripped[7:-1])  # 'import ' ì œê±°í•˜ê³  ';' ì œê±°
        return imports
    
    def _extract_implements(self, class_line: str) -> List[str]:
        """implements ì¸í„°í˜ì´ìŠ¤ ì¶”ì¶œ"""
        if 'implements' not in class_line:
            return []
        
        implements_part = class_line.split('implements')[1].split('{')[0]
        interfaces = [iface.strip() for iface in implements_part.split(',')]
        return interfaces
    
    def _parse_method_signature(self, signature: str) -> Optional[Dict[str, Any]]:
        """ë©”ì†Œë“œ ì‹œê·¸ë‹ˆì²˜ íŒŒì‹±"""
        try:
            # ì „ì²˜ë¦¬: ê°œí–‰ ë¬¸ì ì œê±°, ë‹¤ì¤‘ ê³µë°± ì •ë¦¬
            signature = ' '.join(signature.split())
            
            method_info = {
                "modifiers": [],
                "return_type": None,
                "name": None,
                "parameters": []
            }
            
            # throws ì ˆ ì œê±° (ì„ì‹œ)
            signature_parts = signature.split(' throws ')
            main_signature = signature_parts[0]
            
            # ê´„í˜¸ ìœ„ì¹˜ ì°¾ê¸°
            paren_start = main_signature.find('(')
            if paren_start == -1:
                return None
                
            paren_end = main_signature.rfind(')')
            if paren_end == -1:
                return None
            
            # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ
            params_str = main_signature[paren_start + 1:paren_end]
            if params_str.strip():
                # ì œë„¤ë¦­ íƒ€ì…ì„ ê³ ë ¤í•œ ë§¤ê°œë³€ìˆ˜ íŒŒì‹±
                params = []
                current_param = ""
                angle_bracket_count = 0
                
                for char in params_str:
                    if char == '<':
                        angle_bracket_count += 1
                    elif char == '>':
                        angle_bracket_count -= 1
                    elif char == ',' and angle_bracket_count == 0:
                        if current_param.strip():
                            params.append(current_param.strip())
                        current_param = ""
                        continue
                    
                    current_param += char
                
                if current_param.strip():
                    params.append(current_param.strip())
                
                method_info["parameters"] = params
            
            # ë©”ì†Œë“œ ì´ë¦„ê³¼ ë°˜í™˜ íƒ€ì… ì¶”ì¶œ
            before_params = main_signature[:paren_start].strip()
            parts = before_params.split()
            
            if not parts:
                return None
            
            # ìˆ˜ì •ì ì¶”ì¶œ
            modifiers = ['public', 'private', 'protected', 'static', 'final', 'synchronized', 'abstract']
            i = 0
            while i < len(parts) and parts[i] in modifiers:
                method_info["modifiers"].append(parts[i])
                i += 1
            
            # ë‚˜ë¨¸ì§€ ë¶€ë¶„ì—ì„œ ë°˜í™˜ íƒ€ì…ê³¼ ë©”ì†Œë“œ ì´ë¦„ ì¶”ì¶œ
            remaining_parts = parts[i:]
            
            if len(remaining_parts) >= 1:
                # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ ë©”ì†Œë“œ ì´ë¦„
                method_info["name"] = remaining_parts[-1]
                
                # ê·¸ ì• ë¶€ë¶„ë“¤ì´ ë°˜í™˜ íƒ€ì… (ì œë„¤ë¦­ í¬í•¨)
                if len(remaining_parts) > 1:
                    method_info["return_type"] = ' '.join(remaining_parts[:-1])
                else:
                    # ìƒì„±ìì¸ ê²½ìš°
                    method_info["return_type"] = None
            
            return method_info if method_info["name"] else None
            
        except Exception as e:
            return None


# LLM ì¸í„°í˜ì´ìŠ¤ ì¶”ìƒ í´ë˜ìŠ¤
class LLMInterface(ABC):
    """LLM ì¸í„°í˜ì´ìŠ¤ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def generate_response(self, prompt: str, **kwargs) -> str:
        """ì‘ë‹µ ìƒì„±"""
        pass


class VulnerabilityDetector:
    """ì·¨ì•½ì  íƒì§€ í´ë˜ìŠ¤"""
    
    def __init__(self, llm: Optional[LLMInterface] = None):
        self.llm = llm
    
    def generate_hypothesis(self, func_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """LLMì„ ì‚¬ìš©í•œ ì·¨ì•½ì  ê°€ì„¤ ìƒì„±"""
        # íŒ¨í„´ ë§¤ì¹­ ë°©ì‹ ìš°ì„  ì‚¬ìš© (ë” ì•ˆì •ì )
        pattern_result = self._pattern_based_analysis(func_info)
        
        # LLMì´ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° LLM ê²°ê³¼ì™€ ê²°í•©
        if self.llm:
            try:
                llm_result = self.llm.generate_vulnerability_hypothesis(func_info)
                if llm_result and pattern_result:
                    # ë‘ ê²°ê³¼ë¥¼ ê²°í•©
                    combined_vulns = pattern_result["vulnerabilities"] + llm_result["vulnerabilities"]
                    pattern_result["vulnerabilities"] = combined_vulns
                    pattern_result["analysis_method"] = "pattern_matching + llm"
                elif llm_result:
                    return llm_result
            except Exception as e:
                logging.getLogger(__name__).warning(f"LLM ë¶„ì„ ì‹¤íŒ¨, íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼ë§Œ ì‚¬ìš©: {str(e)}")
        
        return pattern_result
    
    def _pattern_based_analysis(self, func_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """íŒ¨í„´ ê¸°ë°˜ ì·¨ì•½ì  ë¶„ì„"""
        func_name = func_info.get("name", "unknown")
        signature = func_info.get("full_signature", "")
        
        # ì¼ë°˜ì ì¸ ì·¨ì•½ì  íŒ¨í„´ ê²€ì‚¬
        vulnerabilities = []
        
        # 1. Null Pointer Dereference ê²€ì‚¬
        if "null" in signature.lower() or func_name.lower() in ["deserialize", "deserialze"]:
            vulnerabilities.append({
                "type": "NULL_POINTER_DEREFERENCE",
                "description": "ì ì¬ì ì¸ Null Pointer Dereference ì·¨ì•½ì ",
                "severity": "medium",
                "confidence": 0.7
            })
        
        # 2. Type Confusion ê²€ì‚¬
        if "cast" in signature.lower() or "unchecked" in signature.lower():
            vulnerabilities.append({
                "type": "TYPE_CONFUSION", 
                "description": "íƒ€ì… ìºìŠ¤íŒ… ê´€ë ¨ Type Confusion ì·¨ì•½ì ",
                "severity": "high",
                "confidence": 0.8
            })
        
        # 3. Deserialization ì·¨ì•½ì  ê²€ì‚¬
        if any(keyword in func_name.lower() for keyword in ["deserialize", "parse", "decode"]):
            vulnerabilities.append({
                "type": "UNSAFE_DESERIALIZATION",
                "description": "ì•ˆì „í•˜ì§€ ì•Šì€ ì—­ì§ë ¬í™” ì·¨ì•½ì ",
                "severity": "high", 
                "confidence": 0.9
            })
        
        if vulnerabilities:
            return {
                "function": func_name,
                "vulnerabilities": vulnerabilities,
                "analysis_method": "pattern_matching",
                "severity": max(v["severity"] for v in vulnerabilities)
            }
        
        return None
    
    def generate_semgrep_rule(self, vuln_id: int, func_name: str, hypothesis: Dict[str, Any]) -> str:
        """Semgrep ê·œì¹™ ìƒì„±"""
        vulnerabilities = hypothesis.get("vulnerabilities", [])
        
        if not vulnerabilities:
            return ""
        
        # ì²« ë²ˆì§¸ ì·¨ì•½ì ì„ ê¸°ì¤€ìœ¼ë¡œ ê·œì¹™ ìƒì„±
        vuln = vulnerabilities[0]
        vuln_type = vuln["type"]
        
        rule_template = f"""rules:
  - id: vuln-{vuln_id}-{func_name.lower()}
    message: {vuln["description"]}
    severity: {vuln["severity"].upper()}
    languages: [java]
    pattern-either:"""
        
        if vuln_type == "NULL_POINTER_DEREFERENCE":
            rule_template += f"""
      - pattern: |
          public $TYPE {func_name}(...) {{
            ...
            if ($VAR == null) {{
              ...
            }}
            ...
            $VAR.$METHOD(...)
            ...
          }}"""
        
        elif vuln_type == "TYPE_CONFUSION":
            rule_template += f"""
      - pattern: |
          @SuppressWarnings("unchecked")
          public $TYPE {func_name}(...) {{
            ...
            ($CAST_TYPE) $VAR
            ...
          }}"""
        
        elif vuln_type == "UNSAFE_DESERIALIZATION":
            rule_template += f"""
      - pattern: |
          public $TYPE {func_name}(...) {{
            ...
            parser.parseArray(...)
            ...
          }}"""
        
        return rule_template
    
    def generate_codeql_rule(self, vuln_id: int, func_name: str, hypothesis: Dict[str, Any]) -> str:
        """CodeQL ê·œì¹™ ìƒì„±"""
        vulnerabilities = hypothesis.get("vulnerabilities", [])
        
        if not vulnerabilities:
            return ""
        
        vuln = vulnerabilities[0]
        vuln_type = vuln["type"]
        
        rule_template = f"""/**
 * @name {vuln["description"]}
 * @description Detects {vuln_type.lower().replace('_', ' ')} in {func_name}
 * @kind problem
 * @problem.severity {vuln["severity"]}
 * @id java/vuln-{vuln_id}-{func_name.lower()}
 */

import java

"""
        
        if vuln_type == "NULL_POINTER_DEREFERENCE":
            rule_template += f"""from Method m, MethodAccess ma, Variable v
where
  m.getName() = "{func_name}" and
  ma.getEnclosingCallable() = m and
  ma.getQualifier() = v.getAnAccess() and
  exists(EqualityTest eq | 
    eq.getAnOperand() = v.getAnAccess() and
    eq.getAnOperand().(NullLiteral).toString() = "null"
  )
select ma, "Potential null pointer dereference in {func_name}"
"""
        
        elif vuln_type == "TYPE_CONFUSION":
            rule_template += f"""from Method m, CastExpr cast
where
  m.getName() = "{func_name}" and
  cast.getEnclosingCallable() = m and
  m.getAnAnnotation().toString().matches("%SuppressWarnings%")
select cast, "Unsafe type cast in {func_name}"
"""
        
        elif vuln_type == "UNSAFE_DESERIALIZATION":
            rule_template += f"""from Method m, MethodAccess ma
where
  m.getName() = "{func_name}" and
  ma.getEnclosingCallable() = m and
  ma.getMethod().getName().matches("parse%")
select ma, "Unsafe deserialization in {func_name}"
"""
        
        return rule_template
    
    def run_semgrep_analysis(self, rule_file: str, target_path: str) -> Dict[str, Any]:
        """Semgrep ì‹¤í–‰"""
        import subprocess
        import json
        import os
        
        try:
            # Semgrep ê²½ë¡œ ì°¾ê¸°
            semgrep_paths = [
                "/home/user/anaconda3/envs/ace4_sijune/bin/semgrep",
                "/home/ace4_sijune/.local/bin/semgrep",
                "semgrep",
                "python3 -m semgrep"
            ]
            
            semgrep_cmd = None
            for path in semgrep_paths:
                if " " in path:  # python -m semgrep ê²½ìš°
                    try:
                        result = subprocess.run(path.split() + ["--version"], 
                                              capture_output=True, text=True, timeout=10)
                        if result.returncode == 0 or "semgrep" in result.stderr.lower():
                            semgrep_cmd = path.split()
                            break
                    except:
                        continue
                else:
                    if os.path.exists(path) or subprocess.run(["which", path], 
                                                            capture_output=True).returncode == 0:
                        semgrep_cmd = [path]
                        break
            
            if not semgrep_cmd:
                return {
                    "status": "error",
                    "error": "Semgrep not found in any expected location"
                }
            
            # Semgrep ëª…ë ¹ì–´ ì‹¤í–‰
            cmd = semgrep_cmd + [
                "--config", rule_file,
                "--json",
                "--no-git-ignore",
                target_path
            ]
            
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=60
            )
            
            if result.returncode == 0:
                # JSON ê²°ê³¼ íŒŒì‹±
                try:
                    output = json.loads(result.stdout)
                    return {
                        "status": "success",
                        "findings": output.get("results", []),
                        "errors": output.get("errors", [])
                    }
                except json.JSONDecodeError:
                    return {
                        "status": "success", 
                        "findings": [],
                        "raw_output": result.stdout
                    }
            else:
                return {
                    "status": "error",
                    "error": result.stderr,
                    "returncode": result.returncode
                }
                
        except subprocess.TimeoutExpired:
            return {
                "status": "timeout",
                "error": "Semgrep execution timed out"
            }
        except FileNotFoundError:
            return {
                "status": "error",
                "error": "Semgrep not found. Please install semgrep first."
            }
        except Exception as e:
            return {
                "status": "error", 
                "error": str(e)
            }
    
    def run_codeql_analysis(self, rule_file: str, target_path: str, database_path: str = None) -> Dict[str, Any]:
        """CodeQL ì‹¤í–‰"""
        import subprocess
        import json
        import tempfile
        import os
        
        try:
            # CodeQL ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
            if not database_path:
                database_path = f"./codeql_db_{os.getpid()}"
                
                # Java í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ í™•ì¸
                java_dir = os.path.dirname(target_path)
                
                # ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
                create_cmd = [
                    "codeql", "database", "create",
                    database_path,
                    "--language=java",
                    f"--source-root={java_dir}",
                    "--search-path=/opt/codeql-repo"
                ]
                
                create_result = subprocess.run(
                    create_cmd,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                if create_result.returncode != 0:
                    return {
                        "status": "error",
                        "error": f"CodeQL database creation failed: {create_result.stderr}"
                    }
            
            # CodeQL ì¿¼ë¦¬ ì‹¤í–‰
            with tempfile.NamedTemporaryFile(mode='w', suffix='.ql', delete=False) as f:
                f.write(open(rule_file, 'r').read())
                query_file = f.name
            
            try:
                cmd = [
                    "codeql", "query", "run",
                    query_file,
                    "--database", database_path,
                    "--output", f"{query_file}.bqrs",
                    "--search-path=/opt/codeql-repo"
                ]
                
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=60
                )
                
                if result.returncode == 0:
                    # BQRS ê²°ê³¼ë¥¼ CSVë¡œ ë³€í™˜
                    decode_cmd = [
                        "codeql", "bqrs", "decode",
                        f"{query_file}.bqrs",
                        "--format=csv"
                    ]
                    
                    decode_result = subprocess.run(
                        decode_cmd,
                        capture_output=True,
                        text=True
                    )
                    
                    return {
                        "status": "success",
                        "findings": decode_result.stdout.split('\n') if decode_result.returncode == 0 else [],
                        "raw_output": decode_result.stdout
                    }
                else:
                    return {
                        "status": "error",
                        "error": result.stderr,
                        "returncode": result.returncode
                    }
                    
            finally:
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                try:
                    os.unlink(query_file)
                    os.unlink(f"{query_file}.bqrs")
                except:
                    pass
                    
        except subprocess.TimeoutExpired:
            return {
                "status": "timeout",
                "error": "CodeQL execution timed out"
            }
        except FileNotFoundError:
            return {
                "status": "error",
                "error": "CodeQL not found. Please install CodeQL CLI first."
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }


class PatchGenerator:
    """íŒ¨ì¹˜ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, llm: Optional[LLMInterface] = None):
        self.llm = llm
    
    def generate_patch(self, vulnerability: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ì·¨ì•½ì ì— ëŒ€í•œ íŒ¨ì¹˜ ìƒì„±"""
        vuln_type = vulnerability["hypothesis"]["vulnerabilities"][0]["type"]
        func_name = vulnerability["function"]
        
        patch_code = ""
        
        if vuln_type == "NULL_POINTER_DEREFERENCE":
            patch_code = f"""
// íŒ¨ì¹˜: Null ê²€ì‚¬ ì¶”ê°€
public <T> T {func_name}(...) {{
    // Null ê²€ì‚¬ ì¶”ê°€
    if (parser == null) {{
        throw new IllegalArgumentException("Parser cannot be null");
    }}
    if (type == null) {{
        throw new IllegalArgumentException("Type cannot be null");
    }}
    
    // ê¸°ì¡´ ì½”ë“œ...
}}
"""
        
        elif vuln_type == "TYPE_CONFUSION":
            patch_code = f"""
// íŒ¨ì¹˜: ì•ˆì „í•œ íƒ€ì… ìºìŠ¤íŒ…
public <T> T {func_name}(...) {{
    // íƒ€ì… ê²€ì¦ ì¶”ê°€
    if (value != null && !componentType.isInstance(value)) {{
        throw new ClassCastException("Invalid type cast detected");
    }}
    
    // ê¸°ì¡´ ì½”ë“œ...
}}
"""
        
        elif vuln_type == "UNSAFE_DESERIALIZATION":
            patch_code = f"""
// íŒ¨ì¹˜: ì•ˆì „í•œ ì—­ì§ë ¬í™”
public <T> T {func_name}(...) {{
    // ì…ë ¥ ê²€ì¦ ì¶”ê°€
    if (!isValidInputType(componentType)) {{
        throw new SecurityException("Unsafe deserialization attempt");
    }}
    
    // ê¸°ì¡´ ì½”ë“œ...
}}

private boolean isValidInputType(Class<?> type) {{
    // í—ˆìš©ëœ íƒ€ì… ëª©ë¡ ê²€ì‚¬
    return ALLOWED_TYPES.contains(type);
}}
"""
        
        return {
            "vulnerability_id": f"{vulnerability['file']}#{func_name}",
            "patch_type": vuln_type,
            "patch_code": patch_code,
            "description": f"íŒ¨ì¹˜ for {vuln_type} in {func_name}",
            "confidence": 0.8
        }


if __name__ == "__main__":
    # ë©”ì¸ ì‹¤í–‰
    analyzer = VulnerabilityAnalyzer(vuln_id=1)
    result = analyzer.analyze()
    
    if result["status"] == "completed":
        print("âœ… ì·¨ì•½ì  ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ” ë°œê²¬ëœ ì·¨ì•½ì : {len(result['vulnerabilities'])}ê°œ")
        print(f"ğŸ”§ ìƒì„±ëœ íŒ¨ì¹˜: {len(result['patches'])}ê°œ")
    else:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}") 