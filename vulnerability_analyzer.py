#!/usr/bin/env python3
"""
취약점 분석 및 수정 Agent
Author: Assistant
Description: Java 소스코드의 취약점을 분석하고 패치를 생성하는 시스템
"""

import os
import sys
import json
import re
import subprocess
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from abc import ABC, abstractmethod
import logging
from llm_interfaces import LLMFactory, LLMInterface
import difflib
import shutil
import tempfile

def setup_logging(llm_model_name: str = "default"):
    """개선된 로깅 시스템 설정 - LLM 모델별 카테고리별 로거 생성"""
    # 기본 로그 디렉토리들 생성
    log_base_dir = Path("./log")
    log_base_dir.mkdir(exist_ok=True)
    
    # LLM 모델별 서브디렉토리 생성
    model_log_dir = log_base_dir / llm_model_name
    model_log_dir.mkdir(exist_ok=True)
    
    log_subdirs = ["codeql", "semgrep", "response"]
    for subdir in log_subdirs:
        (model_log_dir / subdir).mkdir(exist_ok=True)
    
    # 메인 로그 파일 (모델별)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    main_log_file = model_log_dir / f"vulnerability_analyzer_{timestamp}.log"
    
    # 메인 로거 설정
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(main_log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    # 카테고리별 로거 생성
    main_logger = logging.getLogger(__name__)
    
    # CodeQL 전용 로거 (모델별)
    codeql_logger = logging.getLogger('codeql')
    codeql_handler = logging.FileHandler(
        model_log_dir / "codeql" / f"codeql_execution_{timestamp}.log", 
        encoding='utf-8'
    )
    codeql_handler.setFormatter(logging.Formatter(
        f'%(asctime)s - CodeQL-{llm_model_name} - %(levelname)s - %(message)s'
    ))
    codeql_logger.addHandler(codeql_handler)
    codeql_logger.setLevel(logging.INFO)
    
    # Semgrep 전용 로거 (모델별)
    semgrep_logger = logging.getLogger('semgrep')
    semgrep_handler = logging.FileHandler(
        model_log_dir / "semgrep" / f"semgrep_execution_{timestamp}.log", 
        encoding='utf-8'
    )
    semgrep_handler.setFormatter(logging.Formatter(
        f'%(asctime)s - Semgrep-{llm_model_name} - %(levelname)s - %(message)s'
    ))
    semgrep_logger.addHandler(semgrep_handler)
    semgrep_logger.setLevel(logging.INFO)
    
    # LLM Response 전용 로거 (모델별)
    response_logger = logging.getLogger('llm_response')
    response_handler = logging.FileHandler(
        model_log_dir / "response" / f"llm_responses_{timestamp}.log", 
        encoding='utf-8'
    )
    response_handler.setFormatter(logging.Formatter(
        f'%(asctime)s - LLM_Response-{llm_model_name} - %(levelname)s - %(message)s'
    ))
    response_logger.addHandler(response_handler)
    response_logger.setLevel(logging.INFO)
    
    return main_logger

def get_specialized_logger(category):
    """특화된 로거 반환"""
    return logging.getLogger(category)

class VulnerabilityAnalyzer:
    """메인 취약점 분석 시스템"""
    
    def __init__(self, vuln_id: int = 1, llm_config: Optional[Dict[str, Any]] = None):
        self.vuln_id = vuln_id
        
        # LLM 설정 로드 (로깅 초기화 전에 수행)
        self.llm_config = self._load_llm_config(llm_config)
        self.llm = self._initialize_llm()
        
        # LLM 모델 이름 추출
        self.llm_model_name = self._get_llm_model_name()
        
        # 로깅 시스템 초기화 (모델별)
        self.logger = setup_logging(self.llm_model_name)
        
        self.source_path = Path(f"./benchmark/Java/VUL4J/VUL4J-{vuln_id}")
        self.target_path = self.source_path  # 정적 분석 대상 경로
        
        # 모델별 규칙 디렉토리 생성
        self.rule_dir = Path(f"./rule/VUL4J-{vuln_id}/{self.llm_model_name}")
        self.log_dir = Path(f"./log/{self.llm_model_name}/VUL4J-{vuln_id}")
        
        # 디렉토리 생성
        self.rule_dir.mkdir(parents=True, exist_ok=True)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # 단계별 처리기 초기화
        self.ast_processor = ASTProcessor()
        self.vulnerability_detector = VulnerabilityDetector(self.llm)
        self.patch_generator = PatchGenerator(self.llm)
        
        self.logger.info(f"취약점 분석기 초기화 완료 - ID: {vuln_id}, Model: {self.llm_model_name}")
        if self.llm:
            self.logger.info(f"LLM 연결됨: {self.llm.__class__.__name__}")
    
    def _get_llm_model_name(self) -> str:
        """LLM 모델 이름 추출"""
        if self.llm:
            if hasattr(self.llm, 'model'):
                # 모델명에서 특수문자 제거하여 디렉토리명으로 사용 가능하게 변환
                model_name = str(self.llm.model).replace(':', '_').replace('/', '_').replace('.', '_')
                return model_name
            else:
                return self.llm.__class__.__name__.lower().replace('interface', '')
        return "pattern_matching"
    
    def _load_llm_config(self, llm_config: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """LLM 설정 로드"""
        if llm_config:
            return llm_config
        
        # llm_config.json 파일에서 설정 로드
        config_file = Path("llm_config.json")
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                # 활성화된 LLM 찾기
                for llm_cfg in config_data.get("llm_configs", []):
                    if llm_cfg.get("enabled", False):
                        return llm_cfg
                
                # 기본 LLM 사용
                default_llm_name = config_data.get("default_llm", "qwen")
                for llm_cfg in config_data.get("llm_configs", []):
                    if llm_cfg.get("name") == default_llm_name:
                        return llm_cfg
                        
            except Exception as e:
                self.logger.warning(f"LLM 설정 로드 실패: {str(e)}")
        
        # 기본 설정 반환 (Ollama/Qwen)
        return {
            "type": "ollama",
            "model": "qwen:7b", 
            "base_url": "http://localhost:11434",
            "temperature": 0.1
        }
    
    def _initialize_llm(self) -> Optional[LLMInterface]:
        """LLM 초기화"""
        try:
            llm_type = self.llm_config.get("type", "ollama")
            return LLMFactory.create_llm(llm_type, **self.llm_config)
        except Exception as e:
            self.logger.warning(f"LLM 초기화 실패: {str(e)}")
            self.logger.info("패턴 매칭 방식으로 대체")
            return None
    
    def analyze(self) -> Dict[str, Any]:
        """전체 분석 프로세스 실행"""
        try:
            self.logger.info("=== Stage 1: 사전 작업 시작 ===")
            ast_data = self.stage1_preprocessing()
            
            self.logger.info("=== Stage 2: 취약점 분석 시작 ===")
            vulnerabilities = self.stage2_vulnerability_analysis(ast_data)
            
            self.logger.info("=== Stage 3: 패치 생성 시작 ===")
            patches = self.stage3_patch_generation(vulnerabilities)
            
            result = {
                "vuln_id": self.vuln_id,
                "timestamp": datetime.now().isoformat(),
                "ast_data": ast_data,
                "vulnerabilities": vulnerabilities,
                "patches": patches,
                "status": "completed"
            }
            
            # 결과 저장
            self._save_analysis_result(result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"분석 중 오류 발생: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def stage1_preprocessing(self) -> Dict[str, Any]:
        """Stage 1: AST 노드 추출 및 함수/클래스 단위 분리"""
        self.logger.info("AST 노드 추출 시작")
        
        java_files = list(self.source_path.glob("*.java"))
        if not java_files:
            raise FileNotFoundError(f"Java 파일을 찾을 수 없습니다: {self.source_path}")
        
        ast_data = {}
        for java_file in java_files:
            self.logger.info(f"파일 처리 중: {java_file.name}")
            file_ast = self.ast_processor.extract_ast(java_file)
            ast_data[java_file.name] = file_ast
        
        self.logger.info(f"AST 추출 완료 - {len(ast_data)} 파일 처리")
        return ast_data
    
    def stage2_vulnerability_analysis(self, ast_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Stage 2: 취약점 분석"""
        vulnerabilities = []
        
        for file_name, file_ast in ast_data.items():
            self.logger.info(f"취약점 분석 중: {file_name}")
            
            # 각 함수에 대해 취약점 분석
            for func_info in file_ast.get("functions", []):
                func_name = func_info["name"]
                
                # LLM 취약점 가설 생성
                hypothesis = self.vulnerability_detector.generate_hypothesis(func_info)
                
                if hypothesis:
                    # Semgrep 및 CodeQL 규칙 생성
                    semgrep_rule = self.vulnerability_detector.generate_semgrep_rule(
                        self.vuln_id, func_name, hypothesis
                    )
                    codeql_rule = self.vulnerability_detector.generate_codeql_rule(
                        self.vuln_id, func_name, hypothesis
                    )
                    
                    # 규칙 저장
                    semgrep_rule_file = self._save_rule("semgrep", self.vuln_id, func_name, semgrep_rule)
                    codeql_rule_file = self._save_rule("codeql", self.vuln_id, func_name, codeql_rule)
                    
                    # 실제 정적 분석 도구 실행
                    semgrep_results = None
                    codeql_results = None
                    
                    # Semgrep 비활성화 - CodeQL만 사용
                    # if semgrep_rule_file and semgrep_rule.strip():
                    #     self.logger.info(f"Semgrep 실행 중: {func_name}")
                    #     semgrep_results = self.vulnerability_detector.run_semgrep_analysis(
                    #         str(semgrep_rule_file), 
                    #         str(self.target_path)
                    #     )
                    self.logger.info(f"Semgrep 비활성화됨 - CodeQL만 사용")
                    
                    if codeql_rule_file and codeql_rule.strip():
                        self.logger.info(f"CodeQL 실행 중: {func_name}")
                        codeql_results = self.vulnerability_detector.run_codeql_analysis(
                            str(codeql_rule_file),
                            str(self.target_path)
                        )
                    
                    confirmed = self._is_vulnerability_confirmed(semgrep_results, codeql_results)
                    
                    vulnerability = {
                        "file": file_name,
                        "function": func_name,
                        "hypothesis": hypothesis,
                        "semgrep_rule": semgrep_rule,
                        "codeql_rule": codeql_rule,
                        "severity": hypothesis.get("severity", "medium"),
                        "semgrep_results": semgrep_results,
                        "codeql_results": codeql_results,
                        "confirmed": confirmed
                    }
                    
                    # 검증된 취약점만 결과에 포함 (개발/테스트시에는 모두 포함)
                    vulnerabilities.append(vulnerability)
        
        self.logger.info(f"취약점 분석 완료 - {len(vulnerabilities)}개 발견")
        return vulnerabilities
    
    def stage3_patch_generation(self, vulnerabilities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Stage 3: 패치 생성"""
        patches = []
        
        for vuln in vulnerabilities:
            self.logger.info(f"패치 생성 중: {vuln['function']}")
            
            patch = self.patch_generator.generate_patch(vuln)
            if patch:
                patches.append(patch)
        
        self.logger.info(f"패치 생성 완료 - {len(patches)}개 생성")
        return patches
    
    def _save_rule(self, rule_type: str, vuln_id: int, func_name: str, rule_content: str):
        """규칙 파일 저장"""
        if not rule_content.strip():
            return None
        
        # 디렉토리가 존재하지 않으면 생성
        self.rule_dir.mkdir(parents=True, exist_ok=True)
            
        rule_file = self.rule_dir / f"{rule_type}{vuln_id}-{func_name}"
        with open(rule_file, 'w', encoding='utf-8') as f:
            f.write(rule_content)
        self.logger.info(f"규칙 저장됨: {rule_file}")
        return rule_file
    
    def _is_vulnerability_confirmed(self, semgrep_results: Dict[str, Any], codeql_results: Dict[str, Any]) -> bool:
        """정적 분석 도구 결과를 바탕으로 취약점 확인"""
        confirmed = False
        confidence_score = 0.0
        
        # Semgrep 결과 확인
        if semgrep_results and semgrep_results.get("status") == "success":
            findings = semgrep_results.get("findings", [])
            if findings:
                confirmed = True
                confidence_score += 0.6  # Semgrep 검증시 60% 신뢰도
                self.logger.info(f"Semgrep 검증 성공: {len(findings)}개 발견")
        
        # CodeQL 결과 확인  
        if codeql_results and codeql_results.get("status") == "success":
            findings = codeql_results.get("findings", [])
            if findings and len(findings) > 1:  # CSV 헤더 제외
                confirmed = True
                confidence_score += 0.4  # CodeQL 검증시 40% 신뢰도
                self.logger.info(f"CodeQL 검증 성공: {len(findings)-1}개 발견")
        
        # 검증 실패 로그
        if not confirmed:
            self.logger.warning("정적 분석 도구 검증 실패 - 취약점 미확인")
            
        return confirmed
    
    def _save_analysis_result(self, result: Dict[str, Any]):
        """분석 결과 저장"""
        # 디렉토리가 존재하지 않으면 생성
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        result_file = self.log_dir / f"analysis_result_{self.vuln_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        self.logger.info(f"분석 결과 저장됨: {result_file}")


class ASTProcessor:
    """AST 처리 클래스"""
    
    def extract_ast(self, java_file: Path) -> Dict[str, Any]:
        """Java 파일에서 AST 추출 및 함수/클래스 분리"""
        with open(java_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # 간단한 Java 파싱 (실제로는 JavaParser 등을 사용할 수 있음)
        ast_data = {
            "file_path": str(java_file),
            "content": content,
            "classes": self._extract_classes(content),
            "functions": self._extract_methods(content),
            "imports": self._extract_imports(content)
        }
        
        return ast_data
    
    def _extract_classes(self, content: str) -> List[Dict[str, Any]]:
        """클래스 정보 추출"""
        classes = []
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            if stripped.startswith('public class ') or stripped.startswith('class '):
                class_name = stripped.split()[2] if 'public' in stripped else stripped.split()[1]
                if '{' in class_name:
                    class_name = class_name.split('{')[0]
                
                classes.append({
                    "name": class_name,
                    "line": i + 1,
                    "modifiers": ["public"] if "public" in stripped else [],
                    "interfaces": self._extract_implements(stripped)
                })
        
        return classes
    
    def _extract_methods(self, content: str) -> List[Dict[str, Any]]:
        """메소드 정보 추출 (실제 구현 코드 포함)"""
        methods = []
        lines = content.split('\n')
        
        i = 0
        while i < len(lines):
            stripped = lines[i].strip()
            
            # 어노테이션 건너뛰기
            if stripped.startswith('@'):
                i += 1
                continue
            
            # 메소드 시그니처 패턴 (더 정확하게)
            is_method_line = (
                # 접근 제한자로 시작하는 메소드
                (stripped.startswith('public ') or stripped.startswith('private ') or 
                 stripped.startswith('protected ') or stripped.startswith('static ')) and
                '(' in stripped and
                not stripped.strip().endswith(';') and  # 메소드 선언이 아닌 정의
                not '=' in stripped.split('(')[0] and  # 대입문이 아님
                not stripped.startswith('if ') and     # if문이 아님
                not stripped.startswith('for ') and    # for문이 아님
                not stripped.startswith('while ') and  # while문이 아님
                not '.' in stripped.split('(')[0].split()[-1] and  # 메소드 호출이 아님
                not 'new ' in stripped  # 생성자 호출이 아님
            )
            
            if is_method_line:
                # 메소드 시그니처와 본문을 분리해서 처리
                signature_lines = [stripped]
                j = i + 1
                
                # 시그니처 완성까지 수집 ('{' 또는 'throws' 전까지)
                while j < len(lines):
                    next_line = lines[j].strip()
                    if '{' in next_line:
                        # throws가 있으면 포함
                        if 'throws' in next_line.split('{')[0]:
                            signature_lines.append(next_line.split('{')[0].strip())
                        break
                    elif 'throws' in next_line:
                        signature_lines.append(next_line)
                        j += 1
                        continue
                    elif next_line and not next_line.startswith('//'):
                        signature_lines.append(next_line)
                    j += 1
                
                # 시그니처 정리
                method_signature = ' '.join(signature_lines).strip()
                
                # 메소드 본문 추출 (j 위치부터)
                method_body = self._extract_method_body(lines, j)
                
                method_info = self._parse_method_signature(method_signature)
                if method_info and method_info.get("name"):
                    method_info["line"] = i + 1
                    method_info["body_start"] = j + 1
                    method_info["full_signature"] = method_signature
                    method_info["implementation"] = method_body  # 실제 구현 코드 추가
                    methods.append(method_info)
            
            i += 1
        
        return methods
    
    def _extract_method_body(self, lines: List[str], start_index: int) -> str:
        """메소드 본문 추출"""
        if start_index >= len(lines):
            return ""
        
        method_body_lines = []
        brace_count = 0
        started = False
        
        # start_index부터 시작해서 첫 번째 { 찾기
        for i in range(start_index, len(lines)):
            line = lines[i]
            
            # 첫 번째 { 찾기
            if '{' in line and not started:
                started = True
                # { 이후 부분부터 시작
                brace_part = line[line.find('{'):]
                brace_count += brace_part.count('{')
                brace_count -= brace_part.count('}')
                method_body_lines.append(line)
                
                if brace_count == 0:  # 메소드 끝 (한 줄 메소드)
                    break
            elif started:
                brace_count += line.count('{')
                brace_count -= line.count('}')
                method_body_lines.append(line)
                
                if brace_count == 0:  # 메소드 끝
                    break
        
        return '\n'.join(method_body_lines)
    
    def _extract_imports(self, content: str) -> List[str]:
        """import 문 추출"""
        imports = []
        for line in content.split('\n'):
            stripped = line.strip()
            if stripped.startswith('import ') and stripped.endswith(';'):
                imports.append(stripped[7:-1])  # 'import ' 제거하고 ';' 제거
        return imports
    
    def _extract_implements(self, class_line: str) -> List[str]:
        """implements 인터페이스 추출"""
        if 'implements' not in class_line:
            return []
        
        implements_part = class_line.split('implements')[1].split('{')[0]
        interfaces = [iface.strip() for iface in implements_part.split(',')]
        return interfaces
    
    def _parse_method_signature(self, signature: str) -> Optional[Dict[str, Any]]:
        """메소드 시그니처 파싱"""
        try:
            # 전처리: 개행 문자 제거, 다중 공백 정리
            signature = ' '.join(signature.split())
            
            method_info = {
                "modifiers": [],
                "return_type": None,
                "name": None,
                "parameters": []
            }
            
            # throws 절 제거 (임시)
            signature_parts = signature.split(' throws ')
            main_signature = signature_parts[0]
            
            # 괄호 위치 찾기
            paren_start = main_signature.find('(')
            if paren_start == -1:
                return None
                
            paren_end = main_signature.rfind(')')
            if paren_end == -1:
                return None
            
            # 매개변수 추출
            params_str = main_signature[paren_start + 1:paren_end]
            if params_str.strip():
                # 제네릭 타입을 고려한 매개변수 파싱
                params = []
                current_param = ""
                angle_bracket_count = 0
                
                for char in params_str:
                    if char == '<':
                        angle_bracket_count += 1
                    elif char == '>':
                        angle_bracket_count -= 1
                    elif char == ',' and angle_bracket_count == 0:
                        if current_param.strip():
                            params.append(current_param.strip())
                        current_param = ""
                        continue
                    
                    current_param += char
                
                if current_param.strip():
                    params.append(current_param.strip())
                
                method_info["parameters"] = params
            
            # 메소드 이름과 반환 타입 추출
            before_params = main_signature[:paren_start].strip()
            parts = before_params.split()
            
            if not parts:
                return None
            
            # 수정자 추출
            modifiers = ['public', 'private', 'protected', 'static', 'final', 'synchronized', 'abstract']
            i = 0
            while i < len(parts) and parts[i] in modifiers:
                method_info["modifiers"].append(parts[i])
                i += 1
            
            # 나머지 부분에서 반환 타입과 메소드 이름 추출
            remaining_parts = parts[i:]
            
            if len(remaining_parts) >= 1:
                # 마지막 부분이 메소드 이름
                method_info["name"] = remaining_parts[-1]
                
                # 그 앞 부분들이 반환 타입 (제네릭 포함)
                if len(remaining_parts) > 1:
                    method_info["return_type"] = ' '.join(remaining_parts[:-1])
                else:
                    # 생성자인 경우
                    method_info["return_type"] = None
            
            return method_info if method_info["name"] else None
            
        except Exception as e:
            return None


# LLM 인터페이스 추상 클래스
class LLMInterface(ABC):
    """LLM 인터페이스 추상 클래스"""
    
    @abstractmethod
    def generate_response(self, prompt: str, **kwargs) -> str:
        """응답 생성"""
        pass


class VulnerabilityDetector:
    """취약점 탐지 클래스"""
    
    def __init__(self, llm: Optional[LLMInterface] = None):
        self.llm = llm
        self.logger = setup_logging()
    
    def generate_hypothesis(self, func_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """LLM을 사용한 취약점 가설 생성"""
        
        # LLM이 사용 가능한 경우 LLM 우선 실행
        if self.llm:
            try:
                llm_result = self.llm.generate_vulnerability_hypothesis(func_info)
                if llm_result:
                    self.logger.info(f"LLM 분석 성공: {llm_result.get('analysis_method', 'llm')}")
                    return llm_result
                else:
                    self.logger.warning("LLM 응답이 비어있음, 패턴 매칭으로 대체")
            except Exception as e:
                self.logger.warning(f"LLM 분석 실패, 패턴 매칭으로 대체: {str(e)}")
        else:
            self.logger.info("LLM이 초기화되지 않음, 패턴 매칭 방식 사용")
        
        # LLM 실패 시 패턴 매칭 방식으로 대체
        pattern_result = self._pattern_based_analysis(func_info)
        if pattern_result:
            self.logger.info(f"패턴 매칭 분석 완료: {len(pattern_result.get('vulnerabilities', []))}개 취약점 발견")
        
        return pattern_result
    
    def _pattern_based_analysis(self, func_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """패턴 기반 취약점 분석"""
        func_name = func_info.get("name", "unknown")
        signature = func_info.get("full_signature", "")
        
        # 일반적인 취약점 패턴 검사
        vulnerabilities = []
        
        # 1. Null Pointer Dereference 검사
        if "null" in signature.lower() or func_name.lower() in ["deserialize", "deserialze"]:
            vulnerabilities.append({
                "type": "NULL_POINTER_DEREFERENCE",
                "description": "잠재적인 Null Pointer Dereference 취약점",
                "severity": "medium",
                "confidence": 0.7
            })
        
        # 2. Type Confusion 검사
        if "cast" in signature.lower() or "unchecked" in signature.lower():
            vulnerabilities.append({
                "type": "TYPE_CONFUSION", 
                "description": "타입 캐스팅 관련 Type Confusion 취약점",
                "severity": "high",
                "confidence": 0.8
            })
        
        # 3. Deserialization 취약점 검사
        deserialization_keywords = [
            "deserialize", "deserialze",
            "parse", "decode", "unmarshal", 
            "fromjson", "readvalue", "parsearray", "parseobject"
        ]
        
        if any(keyword in func_name.lower() for keyword in deserialization_keywords):
            vulnerabilities.append({
                "type": "UNSAFE_DESERIALIZATION",
                "description": "UNSAFE_DESERIALIZATION",
                "severity": "high", 
                "confidence": 0.9
            })
        
        if vulnerabilities:
            return {
                "function": func_name,
                "vulnerabilities": vulnerabilities,
                "analysis_method": "pattern_matching",
                "severity": max(v["severity"] for v in vulnerabilities)
            }
        
        return None
    
    def generate_semgrep_rule(self, vuln_id: int, func_name: str, hypothesis: Dict[str, Any]) -> str:
        """Semgrep 규칙 생성"""
        vulnerabilities = hypothesis.get("vulnerabilities", [])
        
        if not vulnerabilities:
            return ""
        
        # UNSAFE_DESERIALIZATION을 우선순위로 선택
        vuln = None
        for v in vulnerabilities:
            if v["type"] == "UNSAFE_DESERIALIZATION":
                vuln = v
                break
        
        # UNSAFE_DESERIALIZATION이 없으면 첫 번째 취약점 사용
        if not vuln:
            vuln = vulnerabilities[0]
            
        vuln_type = vuln["type"]
        
        rule_template = f"""rules:
  - id: vuln-{vuln_id}-{func_name.lower()}
    message: {vuln["description"]}
    severity: {vuln["severity"].upper()}
    languages: [java]
    pattern-either:"""
        
        if vuln_type == "NULL_POINTER_DEREFERENCE":
            rule_template += f"""
      - pattern: |
          public $TYPE {func_name}(...) {{
            ...
            if ($VAR == null) {{
              ...
            }}
            ...
            $VAR.$METHOD(...)
            ...
          }}"""
        
        elif vuln_type == "TYPE_CONFUSION":
            rule_template += f"""
      - pattern: |
          @SuppressWarnings("unchecked")
          public $TYPE {func_name}(...) {{
            ...
            ($CAST_TYPE) $VAR
            ...
          }}"""
        
        elif vuln_type == "UNSAFE_DESERIALIZATION":
            rule_template += f"""
      - pattern: |
          public $TYPE {func_name}(...) {{
            ...
            $PARSER.parseArray(...)
            ...
          }}
      - pattern: |
          $PARSER.parseArray($COMPONENT_TYPE, $ARRAY, $FIELD_NAME)
      - pattern: |
          parser.parseArray(...)
      - pattern: parser.parseArray($ARGS)"""
        
        rule_template += f"""
    metadata:
      category: security
      technology: [java]
      cwe: "CWE-502"
      confidence: HIGH"""
        
        return rule_template
    
    def generate_codeql_rule(self, vuln_id: int, func_name: str, hypothesis: Dict[str, Any]) -> str:
        """향상된 CodeQL 규칙 생성"""
        try:
            # 먼저 취약점 정보 확인
            vulnerabilities = hypothesis.get("vulnerabilities", [])
            if not vulnerabilities:
                return self._generate_simple_fallback_query(vuln_id, func_name)
            
            vuln = vulnerabilities[0]  # 첫 번째 취약점 사용
            vuln_type = vuln.get("type", "Generic")
            description = vuln.get("description", "")
            
            # CodeQL 템플릿 생성기 사용
            from codeql_templates import CodeQLTemplateEngine
            template_generator = CodeQLTemplateEngine()
            
            # 파싱된 정보 생성
            parsed_info = {
                "description": description,
                "vuln_type": vuln_type,
                "func_name": func_name
            }
            
            # 새로운 템플릿 생성기 사용
            return template_generator.generate_codeql_query(vuln_type, func_name, parsed_info)
            
        except Exception as e:
            self.logger.warning(f"CodeQL 규칙 생성 실패: {str(e)}")
            return self._generate_simple_fallback_query(vuln_id, func_name)
    
    def _generate_simple_fallback_query(self, vuln_id: int, func_name: str) -> str:
        """간단한 폴백 쿼리 생성"""
        return f'''/**
 * @name 간단한 메서드 탐지 - {func_name}
 * @description Detects {func_name} method calls
 * @kind problem
 * @problem.severity high
 * @id java/vuln-{vuln_id}-{func_name}-simple
 */

import java

from Method m
where 
  m.getName() = "{func_name}"
select m, "Found {func_name} method at " + m.getLocation().toString()
'''
    
    def _parse_deserialization_info(self, description: str, func_name: str) -> Dict[str, Any]:
        """역직렬화 취약점 정보 파싱 - LLM 응답의 상세 정보 활용"""
        info = {
            "source_patterns": [],
            "sink_patterns": [],
            "taint_tracking": False  # 간단한 패턴 매칭만 사용
        }
        
        # LLM 응답에서 직접 패턴 정보 추출 시도
        # 만약 hypothesis에 상세 정보가 있다면 활용
        # 우선 기본 패턴으로 초기화
        
        # 설명에서 패턴 추출
        desc_lower = description.lower()
        
        # Parser 관련 Source 패턴
        if "parser" in desc_lower or "jsonparser" in desc_lower:
            info["source_patterns"].append({
                "type": "parameter",
                "name": "parser",
                "java_type": "*JSONParser*",
                "position": 0,
                "description": "External JSON parser input"
            })
        
        if "defaultjsonparser" in desc_lower:
            info["source_patterns"].append({
                "type": "parameter", 
                "name": "parser",
                "java_type": "*DefaultJSONParser*",
                "position": 0,
                "description": "Fastjson DefaultJSONParser input"
            })
        
        # Method call sink 패턴
        if "parsearray" in desc_lower:
            info["sink_patterns"].append({
                "type": "method_call",
                "method_name": "parseArray",
                "class_pattern": "*JSONParser*",
                "context": func_name,
                "description": "Dangerous parseArray call"
            })
        
        if "parseobject" in desc_lower:
            info["sink_patterns"].append({
                "type": "method_call",
                "method_name": "parseObject", 
                "class_pattern": "*JSONParser*",
                "context": func_name,
                "description": "Dangerous parseObject call"
            })
        
        if "typeutils.cast" in desc_lower:
            info["sink_patterns"].append({
                "type": "method_call",
                "method_name": "cast",
                "class_pattern": "*TypeUtils*",
                "context": func_name,
                "description": "Unsafe TypeUtils.cast operation"
            })
        
        if "fastjson" in desc_lower:
            info["sink_patterns"].extend([
                {"type": "method_call", "method_name": "parse", "class_pattern": "*JSON*", "context": func_name, "description": "Fastjson parse method"},
                {"type": "method_call", "method_name": "parseObject", "class_pattern": "*JSON*", "context": func_name, "description": "Fastjson parseObject method"}
            ])
        
        return info
    
    def _parse_llm_vulnerability_response_with_patterns(self, vuln: Dict[str, Any], func_name: str, hypothesis: Dict[str, Any]) -> Dict[str, Any]:
        """LLM 응답의 상세 패턴 정보를 포함한 파싱 (새로운 응답 형식 지원)"""
        vuln_type = vuln["type"]
        description = vuln.get("description", "")
        
        # 기본 정보 - 간단한 패턴 매칭만 사용
        parsed = {
            "vuln_type": vuln_type,
            "severity": vuln.get("severity", "medium"),
            "confidence": vuln.get("confidence", 0.5),
            "description": description,
            "func_name": func_name,
            "source_patterns": [],
            "sink_patterns": [],
            "taint_tracking": False  # 간단한 패턴 매칭만 사용
        }
        
        # LLM 응답에 상세 패턴이 있는 경우 직접 사용
        if "source_patterns" in vuln and vuln["source_patterns"]:
            parsed["source_patterns"] = vuln["source_patterns"]
        
        if "sink_patterns" in vuln and vuln["sink_patterns"]:
            parsed["sink_patterns"] = vuln["sink_patterns"]
        
        # 상세 패턴이 없는 경우 기존 방식으로 파싱
        if not parsed["source_patterns"] or not parsed["sink_patterns"]:
            if vuln_type == "UNSAFE_DESERIALIZATION":
                fallback_info = self._parse_deserialization_info(description, func_name)
                if not parsed["source_patterns"]:
                    parsed["source_patterns"] = fallback_info["source_patterns"]
                if not parsed["sink_patterns"]:
                    parsed["sink_patterns"] = fallback_info["sink_patterns"]
            elif vuln_type == "NULL_POINTER_DEREFERENCE":
                fallback_info = self._parse_null_pointer_info(description, func_name)
                parsed.update(fallback_info)
            elif vuln_type == "TYPE_CONFUSION":
                fallback_info = self._parse_type_confusion_info(description, func_name)
                parsed.update(fallback_info)
        
        return parsed
    
    def _parse_null_pointer_info(self, description: str, func_name: str) -> Dict[str, Any]:
        """Null Pointer 취약점 정보 파싱"""
        info = {
            "check_patterns": [],
            "dereference_patterns": []
        }
        
        desc_lower = description.lower()
        
        # 일반적인 null 체크 패턴
        if "null" in desc_lower:
            info["check_patterns"].extend([
                {"type": "null_check", "pattern": "== null"},
                {"type": "null_check", "pattern": "!= null"}
            ])
            
            info["dereference_patterns"].extend([
                {"type": "field_access", "pattern": "*.field"},
                {"type": "method_call", "pattern": "*.method()"}
            ])
        
        return info
    
    def _parse_type_confusion_info(self, description: str, func_name: str) -> Dict[str, Any]:
        """Type Confusion 취약점 정보 파싱"""
        info = {
            "cast_patterns": [],
            "type_patterns": []
        }
        
        desc_lower = description.lower()
        
        if "cast" in desc_lower or "type" in desc_lower:
            info["cast_patterns"].append({
                "type": "unsafe_cast",
                "context": func_name
            })
        
        return info
    
    def _generate_dynamic_codeql_rule(self, vuln_id: int, func_name: str, vuln: Dict[str, Any], parsed_info: Dict[str, Any]) -> str:
        """동적 CodeQL 규칙 생성 - 간단한 패턴 매칭 버전"""
        vuln_type = vuln.get("type", "UNKNOWN")
        description = self._generate_description(vuln_type, func_name, parsed_info)
        
        # 헤더 생성
        header = f'''/**
 * @name {description}
 * @description Detects {vuln_type.lower()} in {func_name}
 * @kind problem
 * @problem.severity high
 * @id java/vuln-{vuln_id}-{func_name}
 */

'''
        
        # 간단한 패턴 기반 쿼리 생성 (DataFlow 없이)
        if vuln_type == "UNSAFE_DESERIALIZATION":
            query = self._generate_simple_deserialization_query(func_name, parsed_info)
        elif vuln_type == "NULL_POINTER_DEREFERENCE":
            query = self._generate_simple_null_pointer_query(func_name, parsed_info)
        elif vuln_type == "TYPE_CONFUSION":
            query = self._generate_simple_type_confusion_query(func_name, parsed_info)
        else:
            query = self._generate_simple_generic_query(func_name, parsed_info)
        
        return header + query
    
    def _generate_simple_deserialization_query(self, func_name: str, parsed_info: Dict[str, Any]) -> str:
        """간단한 역직렬화 쿼리 (기본 java 모듈만 사용)"""
        return f'''import java

from Method m, MethodAccess ma
where 
  m.getName() = "{func_name}" and
  ma.getEnclosingCallable() = m and
  (
    ma.getMethod().getName() = "parseArray" or
    ma.getMethod().getName() = "parseObject" or  
    ma.getMethod().getName() = "parse" or
    ma.getMethod().getName() = "readValue"
  ) and
  ma.getMethod().getDeclaringType().getName().matches("%JSON%")
select ma, "Potentially unsafe deserialization in " + m.getName() + " at line " + ma.getLocation().getStartLine()
'''
    
    def _generate_simple_null_pointer_query(self, func_name: str, parsed_info: Dict[str, Any]) -> str:
        """간단한 Null Pointer 쿼리"""
        return f'''import java

from Method m, Variable v, VarAccess va
where 
  m.getName() = "{func_name}" and
  va.getEnclosingCallable() = m and
  va.getVariable() = v and
  (
    // 체크 없이 사용되는 변수 접근
    not exists(EqualityTest et | 
      et.getAnOperand() = va.getVariable().getAnAccess() and
      et.getAnOperand().(NullLiteral).getValue() = "null"
    )
  ) and
  // 메서드 호출이나 필드 접근
  (
    exists(MethodAccess ma | ma.getQualifier() = va) or
    exists(FieldAccess fa | fa.getQualifier() = va)
  )
select va, "Potential null pointer dereference of variable " + v.getName() + " in " + m.getName()
'''
    
    def _generate_simple_type_confusion_query(self, func_name: str, parsed_info: Dict[str, Any]) -> str:
        """간단한 Type Confusion 쿼리"""
        return f'''import java

from Method m, CastExpr cast
where 
  m.getName() = "{func_name}" and
  cast.getEnclosingCallable() = m and
  // 안전하지 않은 캐스팅 패턴
  not exists(InstanceOfExpr iof | 
    iof.getExpr() = cast.getExpr()
  )
select cast, "Unsafe type cast in " + m.getName() + " - missing instanceof check"
'''
    
    def _generate_simple_generic_query(self, func_name: str, parsed_info: Dict[str, Any]) -> str:
        """간단한 일반 취약점 쿼리"""
        return f'''import java

from Method m, MethodAccess ma
where 
  m.getName() = "{func_name}" and
  ma.getEnclosingCallable() = m and
  (
    ma.getMethod().getName().matches("parse%") or
    ma.getMethod().getName().matches("read%") or  
    ma.getMethod().getName().matches("deserialize%")
  )
select ma, "Potentially dangerous method call in " + m.getName() + ": " + ma.getMethod().getName()
'''
    
    def _generate_description(self, vuln_type: str, func_name: str, parsed_info: Dict[str, Any]) -> str:
        """동적 설명 생성"""
        base_desc = f"Detects {vuln_type.lower().replace('_', ' ')} in {func_name}"
        
        if vuln_type == "UNSAFE_DESERIALIZATION":
            if parsed_info.get("sink_patterns"):
                methods = [p.get("method_name", "") for p in parsed_info["sink_patterns"] if p.get("method_name")]
                if methods:
                    base_desc += f" involving {', '.join(set(methods))}"
        
        return base_desc
    
    def _generate_deserialization_rule(self, func_name: str, parsed_info: Dict[str, Any]) -> str:
        """역직렬화 규칙 동적 생성"""
        rule_parts = []
        
        # Taint tracking이 필요한 경우
        if parsed_info.get("taint_tracking", False):
            rule_parts.append("import semmle.code.java.dataflow.DataFlow")
            rule_parts.append("import semmle.code.java.dataflow.TaintTracking")
            rule_parts.append("")
            
            # Source 클래스 생성
            source_classes = self._generate_source_classes(func_name, parsed_info["source_patterns"])
            rule_parts.extend(source_classes)
            
            # Sink 클래스 생성
            sink_classes = self._generate_sink_classes(func_name, parsed_info["sink_patterns"])
            rule_parts.extend(sink_classes)
            
            # Configuration 클래스 생성
            config_class = self._generate_taint_config(func_name)
            rule_parts.append(config_class)
            
            # Query 생성
            query = self._generate_taint_query(func_name)
            rule_parts.append(query)
        else:
            # 간단한 패턴 매칭 규칙
            simple_rule = self._generate_simple_pattern_rule(func_name, parsed_info)
            rule_parts.append(simple_rule)
        
        return "\n".join(rule_parts)
    
    def _generate_source_classes(self, func_name: str, source_patterns: List[Dict[str, Any]]) -> List[str]:
        """Source 클래스들 동적 생성 - 개선된 패턴 지원"""
        classes = []
        
        for i, pattern in enumerate(source_patterns):
            class_name = f"VulnSource{i+1}" if len(source_patterns) > 1 else "VulnSource"
            
            if pattern["type"] == "parameter":
                # 새로운 형식과 기존 형식 모두 지원
                java_type = pattern.get("java_type", pattern.get("name_pattern", "*"))
                position = pattern.get("position", 0)
                description = pattern.get("description", "External input parameter")
                
                classes.append(f"""/**
 * Source: {description}
 */
class {class_name} extends DataFlow::Node {{
  {class_name}() {{
    exists(Method m, Parameter p |
      m.getName() = "{func_name}" and
      p = m.getParameter({position}) and
      p.getType().getName().matches("{java_type}") and
      this.asParameter() = p
    )
  }}
}}
""")
            elif pattern["type"] == "field":
                # 필드 소스 패턴
                field_pattern = pattern.get("name", "*")
                java_type = pattern.get("java_type", "*")
                description = pattern.get("description", "Dangerous field access")
                
                classes.append(f"""/**
 * Source: {description}
 */
class {class_name} extends DataFlow::Node {{
  {class_name}() {{
    exists(Field f, FieldAccess fa |
      f.getName().matches("{field_pattern}") and
      f.getType().getName().matches("{java_type}") and
      fa.getField() = f and
      this.asExpr() = fa
    )
  }}
}}
""")
            elif pattern["type"] == "method_return":
                # 메서드 반환값 소스 패턴
                method_pattern = pattern.get("name", "*")
                java_type = pattern.get("java_type", "*")
                description = pattern.get("description", "Method return value")
                
                classes.append(f"""/**
 * Source: {description}
 */
class {class_name} extends DataFlow::Node {{
  {class_name}() {{
    exists(MethodAccess ma |
      ma.getMethod().getName().matches("{method_pattern}") and
      ma.getMethod().getReturnType().getName().matches("{java_type}") and
      this.asExpr() = ma
    )
  }}
}}
""")
        
        return classes
    
    def _generate_sink_classes(self, func_name: str, sink_patterns: List[Dict[str, Any]]) -> List[str]:
        """Sink 클래스들 동적 생성 - 개선된 패턴 지원"""
        classes = []
        
        for i, pattern in enumerate(sink_patterns):
            class_name = f"VulnSink{i+1}" if len(sink_patterns) > 1 else "VulnSink"
            
            if pattern["type"] == "method_call":
                method_name = pattern["method_name"]
                class_pattern = pattern.get("class_pattern", "*")
                context = pattern.get("context", func_name)
                description = pattern.get("description", "Dangerous method call")
                
                classes.append(f"""/**
 * Sink: {description}
 */
class {class_name} extends DataFlow::Node {{
  {class_name}() {{
    exists(MethodAccess ma |
      ma.getMethod().getName() = "{method_name}" and
      ma.getEnclosingCallable().getName() = "{context}" and
      ma.getMethod().getDeclaringType().getName().matches("{class_pattern}") and
      this.asExpr() = ma
    )
  }}
}}
""")
            elif pattern["type"] == "field_access":
                # 필드 접근 sink 패턴
                field_pattern = pattern.get("field_name", "*")
                class_pattern = pattern.get("class_pattern", "*")
                description = pattern.get("description", "Dangerous field access")
                
                classes.append(f"""/**
 * Sink: {description}
 */
class {class_name} extends DataFlow::Node {{
  {class_name}() {{
    exists(FieldAccess fa |
      fa.getField().getName().matches("{field_pattern}") and
      fa.getField().getDeclaringType().getName().matches("{class_pattern}") and
      this.asExpr() = fa
    )
  }}
}}
""")
            elif pattern["type"] == "cast":
                # 타입 캐스팅 sink 패턴
                target_type = pattern.get("target_type", "*")
                description = pattern.get("description", "Unsafe type cast")
                
                classes.append(f"""/**
 * Sink: {description}
 */
class {class_name} extends DataFlow::Node {{
  {class_name}() {{
    exists(CastExpr cast |
      cast.getEnclosingCallable().getName() = "{func_name}" and
      cast.getType().getName().matches("{target_type}") and
      this.asExpr() = cast
    )
  }}
}}
""")
        
        return classes
    
    def _generate_taint_config(self, func_name: str) -> str:
        """Taint tracking configuration 생성"""
        return f"""/**
 * Taint tracking configuration for {func_name}
 */
class VulnConfig extends TaintTracking::Configuration {{
  VulnConfig() {{ this = "VulnConfig" }}
  
  override predicate isSource(DataFlow::Node source) {{
    source instanceof VulnSource
  }}
  
  override predicate isSink(DataFlow::Node sink) {{
    sink instanceof VulnSink
  }}
}}
"""
    
    def _generate_taint_query(self, func_name: str) -> str:
        """Taint tracking query 생성"""
        return f"""from VulnConfig config, DataFlow::PathNode source, DataFlow::PathNode sink
where config.hasFlowPath(source, sink)
select sink.getNode(), source, sink, "Security vulnerability in {func_name} - data flow from $@ to $@", 
       source.getNode(), "external input", sink.getNode(), "dangerous operation"
"""
    
    def _generate_null_pointer_rule(self, func_name: str, parsed_info: Dict[str, Any]) -> str:
        """Null Pointer 규칙 동적 생성"""
        return f"""from Method m, MethodAccess ma, Variable v
where
  m.getName() = "{func_name}" and
  ma.getEnclosingCallable() = m and
  ma.getQualifier() = v.getAnAccess() and
  not exists(EqualityTest eq | 
    eq.getAnOperand() = v.getAnAccess() and
    eq.getAnOperand().(NullLiteral).toString() = "null" and
    eq.getLocation().getStartLine() < ma.getLocation().getStartLine()
  )
select ma, "Potential null pointer dereference in {func_name} - variable may be null"
"""
        
    def _generate_type_confusion_rule(self, func_name: str, parsed_info: Dict[str, Any]) -> str:
        """Type Confusion 규칙 동적 생성"""
        return f"""from Method m, CastExpr cast
where
  m.getName() = "{func_name}" and
  cast.getEnclosingCallable() = m and
  not exists(InstanceOfExpr ioe |
    ioe.getLocation().getStartLine() < cast.getLocation().getStartLine() and
    ioe.getLocation().getStartLine() > cast.getLocation().getStartLine() - 10
  )
select cast, "Unsafe type cast in {func_name} - missing type check"
"""
    
    def _generate_generic_rule(self, func_name: str, parsed_info: Dict[str, Any]) -> str:
        """일반적인 규칙 생성"""
        return f"""from Method m
where
  m.getName() = "{func_name}"
select m, "Potential security vulnerability in {func_name}"
"""
    
    def _generate_simple_pattern_rule(self, func_name: str, parsed_info: Dict[str, Any]) -> str:
        """간단한 패턴 매칭 규칙 생성"""
        sink_patterns = parsed_info.get("sink_patterns", [])
        
        if sink_patterns:
            method_names = [p.get("method_name") for p in sink_patterns if p.get("method_name")]
            if method_names:
                method_condition = " or ".join([f'ma.getMethod().getName() = "{name}"' for name in method_names])
                return f"""from Method m, MethodAccess ma
where
  m.getName() = "{func_name}" and
  ma.getEnclosingCallable() = m and
  ({method_condition})
select ma, "Dangerous method call in {func_name}"
"""
        
        return self._generate_generic_rule(func_name, parsed_info)
    
    def run_semgrep_analysis(self, rule_file: str, target_path: str) -> Dict[str, Any]:
        """Semgrep 실행"""
        import subprocess
        import json
        import os
        
        # Semgrep 전용 로거 사용
        semgrep_logger = get_specialized_logger('semgrep')
        
        try:
            semgrep_logger.info(f"=== Semgrep 분석 시작 ===")
            semgrep_logger.info(f"규칙 파일: {rule_file}")
            semgrep_logger.info(f"대상 경로: {target_path}")
            
            # PATH에 로컬 bin 추가
            env = os.environ.copy()
            env['PATH'] = f"{os.path.expanduser('~/.local/bin')}:{env.get('PATH', '')}"
            
            # Semgrep 경로 찾기 (개선된 순서)
            semgrep_paths = [
                os.path.expanduser("~/.local/bin/semgrep"),
                "/home/ace4_sijune/.local/bin/semgrep", 
                "semgrep"
            ]
            
            semgrep_cmd = None
            for path in semgrep_paths:
                try:
                    result = subprocess.run([path, "--version"], 
                                          capture_output=True, text=True, timeout=10, env=env)
                    if result.returncode == 0:
                        semgrep_cmd = [path]
                        semgrep_logger.info(f"Semgrep 경로 확인: {path}")
                        semgrep_logger.info(f"Semgrep 버전: {result.stdout.strip()}")
                        break
                except:
                    continue
            
            if not semgrep_cmd:
                semgrep_logger.error("Semgrep 실행 파일을 찾을 수 없음")
                return {
                    "status": "error",
                    "error": "Semgrep not found in any expected location"
                }
            
            # Semgrep 명령어 실행
            cmd = semgrep_cmd + [
                "--config", rule_file,
                "--json",
                "--no-git-ignore",
                target_path
            ]
            
            semgrep_logger.info(f"실행 명령어: {' '.join(cmd)}")
            
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=60,
                env=env
            )
            
            semgrep_logger.info(f"반환 코드: {result.returncode}")
            if result.stdout:
                semgrep_logger.info(f"표준 출력 (일부): {result.stdout[:200]}...")
            if result.stderr:
                semgrep_logger.warning(f"표준 에러: {result.stderr}")
            
            if result.returncode == 0:
                # JSON 결과 파싱
                try:
                    output = json.loads(result.stdout)
                    findings = output.get("results", [])
                    errors = output.get("errors", [])
                    
                    semgrep_logger.info(f"Semgrep 분석 완료 - {len(findings)}개 발견, {len(errors)}개 오류")
                    
                    # 각 발견사항 로깅
                    for i, finding in enumerate(findings):
                        semgrep_logger.info(f"발견 #{i+1}: {finding.get('check_id', 'N/A')} at {finding.get('path', 'N/A')}:{finding.get('start', {}).get('line', 'N/A')}")
                        if finding.get('extra', {}).get('message'):
                            semgrep_logger.info(f"  메시지: {finding['extra']['message']}")
                    
                    return {
                        "status": "success",
                        "findings": findings,
                        "errors": errors
                    }
                except json.JSONDecodeError as e:
                    semgrep_logger.error(f"JSON 파싱 실패: {str(e)}")
                    return {
                        "status": "success", 
                        "findings": [],
                        "raw_output": result.stdout
                    }
            else:
                semgrep_logger.error(f"Semgrep 실행 실패 (코드 {result.returncode}): {result.stderr}")
                return {
                    "status": "error",
                    "error": result.stderr,
                    "returncode": result.returncode
                }
                
        except subprocess.TimeoutExpired:
            semgrep_logger.error("Semgrep 실행 시간 초과 (60초)")
            return {
                "status": "timeout",
                "error": "Semgrep execution timed out"
            }
        except FileNotFoundError:
            semgrep_logger.error("Semgrep 실행 파일 없음 - 설치 필요")
            return {
                "status": "error",
                "error": "Semgrep not found. Please install semgrep first."
            }
        except Exception as e:
            semgrep_logger.error(f"예상치 못한 오류: {str(e)}")
            return {
                "status": "error",
                "error": str(e)
            }
    
    def run_codeql_analysis(self, rule_file: str, target_path: str, database_path: str = None) -> Dict[str, Any]:
        """CodeQL 실행"""
        import subprocess
        import json
        import tempfile
        import os
        
        # CodeQL 전용 로거 사용
        codeql_logger = get_specialized_logger('codeql')
        
        try:
            codeql_logger.info(f"=== CodeQL 분석 시작 ===")
            codeql_logger.info(f"규칙 파일: {rule_file}")
            codeql_logger.info(f"대상 경로: {target_path}")
            codeql_logger.info(f"데이터베이스 경로: {database_path}")
            
            # CodeQL 데이터베이스가 없으면 기존에 생성된 DB 사용 또는 새로 생성
            if not database_path:
                # 기존에 생성된 DB가 있는지 확인
                existing_db = "./codeql/test_db"
                if os.path.exists(existing_db):
                    database_path = existing_db
                    codeql_logger.info(f"기존 CodeQL DB 사용: {database_path}")
                    self.logger.info(f"기존 CodeQL DB 사용: {database_path}")
                else:
                    # 새로 생성
                    codeql_dir = "./codeql"
                    os.makedirs(codeql_dir, exist_ok=True)
                    database_path = f"{codeql_dir}/codeql_db_{os.getpid()}"
                    
                    # 기존 데이터베이스가 있으면 삭제
                    if os.path.exists(database_path):
                        codeql_logger.info(f"기존 DB 삭제: {database_path}")
                        import shutil
                        shutil.rmtree(database_path, ignore_errors=True)
                    
                    codeql_logger.info(f"새 CodeQL DB 생성: {database_path}")
                    
                    # Maven 프로젝트 사용
                    maven_project = "./maven-project"
                    if not os.path.exists(maven_project):
                        codeql_logger.info(f"Maven 프로젝트 생성: {maven_project}")
                        # Maven 프로젝트가 없으면 생성
                        os.makedirs(f"{maven_project}/src/main/java/com/alibaba/fastjson/serializer", exist_ok=True)
                        # 대상 파일 복사
                        import shutil
                        shutil.copy2(target_path, f"{maven_project}/src/main/java/com/alibaba/fastjson/serializer/")
                        codeql_logger.info(f"소스 파일 복사: {target_path} -> Maven 프로젝트")
                
                # 데이터베이스 생성
                create_cmd = [
                    "codeql", "database", "create",
                    database_path,
                    "--language=java",
                    f"--source-root={maven_project}",
                    "--overwrite"  # 기존 데이터베이스 덮어쓰기
                ]
                
                codeql_logger.info(f"DB 생성 명령어: {' '.join(create_cmd)}")
                
                create_result = subprocess.run(
                    create_cmd,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                codeql_logger.info(f"DB 생성 반환 코드: {create_result.returncode}")
                if create_result.stdout:
                    codeql_logger.info(f"DB 생성 출력: {create_result.stdout}")
                if create_result.stderr:
                    codeql_logger.warning(f"DB 생성 에러: {create_result.stderr}")
                
                if create_result.returncode != 0:
                    codeql_logger.error("CodeQL 데이터베이스 생성 실패")
                    return {
                        "status": "error",
                        "error": f"CodeQL database creation failed: {create_result.stderr}"
                    }
            
            # CodeQL 쿼리 실행 - .ql 확장자 확인
            if not rule_file.endswith('.ql'):
                # .ql 확장자가 없으면 복사본 생성
                ql_file = rule_file + '.ql'
                import shutil
                shutil.copy2(rule_file, ql_file)
                query_file = ql_file
                codeql_logger.info(f"쿼리 파일 확장자 추가: {rule_file} -> {ql_file}")
            else:
                query_file = rule_file
                codeql_logger.info(f"쿼리 파일 사용: {query_file}")
            
            try:
                # 쿼리 파일 확장자 추가
                if not query_file.endswith('.ql'):
                    new_query_file = f"{query_file}.ql"
                    shutil.copy2(query_file, new_query_file)
                    query_file = new_query_file
                    codeql_logger.info(f"쿼리 파일 확장자 추가: {query_file}")
                
                # qlpack.yml 파일 생성 (없는 경우)
                query_dir = os.path.dirname(query_file)
                qlpack_file = os.path.join(query_dir, "qlpack.yml")
                if not os.path.exists(qlpack_file):
                    qlpack_content = """name: vuln4j-queries
version: 1.0.0
dependencies:
  codeql/java-all: "*"
"""
                    with open(qlpack_file, 'w') as f:
                        f.write(qlpack_content)
                    codeql_logger.info(f"qlpack.yml 생성됨: {qlpack_file}")
                
                # 상대 경로로 데이터베이스 경로 계산
                rel_database_path = os.path.relpath(database_path, query_dir)
                output_file = f"{os.path.basename(query_file)}.bqrs"
                
                # 쿼리 디렉토리에서 실행
                original_cwd = os.getcwd()
                os.chdir(query_dir)
                
                cmd = [
                    "codeql", "query", "run",
                    os.path.basename(query_file),
                    "--database", rel_database_path,
                    "--output", output_file
                ]
                
                codeql_logger.info(f"쿼리 실행 명령어: {' '.join(cmd)}")
                
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=60
                )
                
                codeql_logger.info(f"쿼리 실행 반환 코드: {result.returncode}")
                if result.stdout:
                    codeql_logger.info(f"쿼리 실행 출력: {result.stdout}")
                if result.stderr:
                    codeql_logger.warning(f"쿼리 실행 에러: {result.stderr}")
                
                if result.returncode == 0:
                    # BQRS 결과를 CSV로 변환
                    decode_cmd = [
                        "codeql", "bqrs", "decode",
                        output_file,
                        "--format=csv"
                    ]
                    
                    codeql_logger.info(f"결과 디코딩 명령어: {' '.join(decode_cmd)}")
                    
                    decode_result = subprocess.run(
                        decode_cmd,
                        capture_output=True,
                        text=True
                    )
                    
                    codeql_logger.info(f"디코딩 반환 코드: {decode_result.returncode}")
                    if decode_result.stdout:
                        findings = decode_result.stdout.split('\n')
                        codeql_logger.info(f"CodeQL 분석 완료 - {len([f for f in findings if f.strip()])}개 결과")
                        for i, finding in enumerate(findings[:5]):  # 처음 5개만 로깅
                            if finding.strip():
                                codeql_logger.info(f"결과 #{i+1}: {finding}")
                    if decode_result.stderr:
                        codeql_logger.warning(f"디코딩 에러: {decode_result.stderr}")
                    
                    return {
                        "status": "success",
                        "findings": decode_result.stdout.split('\n') if decode_result.returncode == 0 else [],
                        "raw_output": decode_result.stdout
                    }
                else:
                    codeql_logger.error(f"CodeQL 쿼리 실행 실패 (코드 {result.returncode}): {result.stderr}")
                    return {
                        "status": "error",
                        "error": result.stderr,
                        "returncode": result.returncode
                    }
                    
            finally:
                # 원래 디렉토리로 복원
                try:
                    os.chdir(original_cwd)
                except:
                    pass
                
                # 임시 파일 정리
                try:
                    if query_file != rule_file and os.path.exists(query_file):  # 복사본인 경우만 삭제
                        os.unlink(query_file)
                        codeql_logger.info(f"임시 쿼리 파일 삭제: {query_file}")
                    
                    # BQRS 파일 경로 수정
                    bqrs_path = os.path.join(query_dir, output_file) if 'query_dir' in locals() and 'output_file' in locals() else f"{query_file}.bqrs"
                    if os.path.exists(bqrs_path):
                        os.unlink(bqrs_path)
                        codeql_logger.info(f"BQRS 파일 삭제: {bqrs_path}")
                except Exception as e:
                    codeql_logger.warning(f"임시 파일 정리 실패: {str(e)}")
                    
        except subprocess.TimeoutExpired:
            codeql_logger.error("CodeQL 실행 시간 초과 (60초)")
            return {
                "status": "timeout",
                "error": "CodeQL execution timed out"
            }
        except FileNotFoundError:
            codeql_logger.error("CodeQL 실행 파일 없음 - 설치 필요")
            return {
                "status": "error",
                "error": "CodeQL not found. Please install CodeQL CLI first."
            }
        except Exception as e:
            codeql_logger.error(f"예상치 못한 오류: {str(e)}")
            return {
                "status": "error",
                "error": str(e)
            }


class PatchGenerator:
    """패치 생성 클래스"""
    
    def __init__(self, llm: Optional[LLMInterface] = None):
        self.llm = llm
    
    def generate_patch(self, vulnerability: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """취약점에 대한 패치 생성"""
        vuln_type = vulnerability["hypothesis"]["vulnerabilities"][0]["type"]
        func_name = vulnerability["function"]
        
        patch_code = ""
        
        if vuln_type == "NULL_POINTER_DEREFERENCE":
            patch_code = f"""
// 패치: Null 검사 추가
public <T> T {func_name}(...) {{
    // Null 검사 추가
    if (parser == null) {{
        throw new IllegalArgumentException("Parser cannot be null");
    }}
    if (type == null) {{
        throw new IllegalArgumentException("Type cannot be null");
    }}
    
    // 기존 코드...
}}
"""
        
        elif vuln_type == "TYPE_CONFUSION":
            patch_code = f"""
// 패치: 안전한 타입 캐스팅
public <T> T {func_name}(...) {{
    // 타입 검증 추가
    if (value != null && !componentType.isInstance(value)) {{
        throw new ClassCastException("Invalid type cast detected");
    }}
    
    // 기존 코드...
}}
"""
        
        elif vuln_type == "UNSAFE_DESERIALIZATION":
            patch_code = f"""
// 패치: 안전한 역직렬화
public <T> T {func_name}(...) {{
    // 입력 검증 추가
    if (!isValidInputType(componentType)) {{
        throw new SecurityException("Unsafe deserialization attempt");
    }}
    
    // 기존 코드...
}}

private boolean isValidInputType(Class<?> type) {{
    // 허용된 타입 목록 검사
    return ALLOWED_TYPES.contains(type);
}}
"""
        
        return {
            "vulnerability_id": f"{vulnerability['file']}#{func_name}",
            "patch_type": vuln_type,
            "patch_code": patch_code,
            "description": f"패치 for {vuln_type} in {func_name}",
            "confidence": 0.8
        }


class PatchSimilarityEngine:
    """유사도 기반 패치 생성 엔진"""
    
    def __init__(self):
        self.patch_templates = {
            "NULL_POINTER_DEREFERENCE": [
                "if ({param} == null) {{ throw new IllegalArgumentException(\"{param} cannot be null\"); }}",
                "if ({param} == null) {{ return null; }}",
                "if ({param} == null) {{ {param} = new {type}(); }}",
                "Objects.requireNonNull({param}, \"{param} must not be null\");"
            ],
            "UNSAFE_DESERIALIZATION": [
                "if (!isValidInput({param})) {{ throw new SecurityException(\"Invalid input for deserialization\"); }}",
                "validateDeserializationInput({param});",
                "if ({param} instanceof UntrustedInput) {{ throw new SecurityException(\"Untrusted input detected\"); }}",
                "sanitizeInput({param});"
            ],
            "TYPE_CONFUSION": [
                "if (!({param} instanceof {expected_type})) {{ throw new ClassCastException(\"Expected {expected_type}\"); }}",
                "if ({param}.getClass() != {expected_type}.class) {{ return null; }}",
                "validateType({param}, {expected_type}.class);"
            ]
        }
    
    def sim(self, a: str, b: str, depth: int = 0) -> float:
        """
        유사도 계산 함수 - 제공된 알고리즘 기반
        
        Args:
            a, b: 비교할 코드 문장들
            depth: 재귀 깊이 (무한 재귀 방지)
            
        Returns:
            float: 유사도 (0.0 ~ 1.0)
        """
        if not a or not b or depth > 5:  # 최대 재귀 깊이 제한
            return 0.0
            
        # Atomic statements (단일 문장) 처리
        if self._is_atomic_stmt(a) and self._is_atomic_stmt(b):
            return self._edit_distance_similarity(a, b)
        
        # Ensembled statements (복합 문장) 처리
        elif self._is_ensembled_stmt(a) and self._is_ensembled_stmt(b):
            return self._ensembled_similarity(a, b, depth + 1)
        
        # Otherwise
        else:
            return 0.0
    
    def _is_atomic_stmt(self, stmt: str) -> bool:
        """원자적 문장인지 확인"""
        # 단일 라인이고 복합 구조가 없는 경우
        lines = stmt.strip().split('\n')
        if len(lines) != 1:
            return False
        
        # 제어 구조나 블록이 없는 경우
        atomic_indicators = ['{', '}', 'if', 'for', 'while', 'try', 'catch']
        return not any(indicator in stmt.lower() for indicator in atomic_indicators)
    
    def _is_ensembled_stmt(self, stmt: str) -> bool:
        """복합 문장인지 확인"""
        return not self._is_atomic_stmt(stmt)
    
    def _edit_distance_similarity(self, a: str, b: str) -> float:
        """편집 거리 기반 유사도 계산"""
        if len(a) == 0:
            return 0.0 if len(b) > 0 else 1.0
            
        # Levenshtein distance 계산
        edit_distance = self._levenshtein_distance(a, b)
        max_length = max(len(a), len(b))
        
        # 편집 거리를 길이로 정규화
        return 1.0 - (edit_distance / max_length)
    
    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """Levenshtein 편집 거리 계산"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    def _ensembled_similarity(self, a: str, b: str, depth: int = 0) -> float:
        """복합 문장의 유사도 계산"""
        # 문장을 구성 요소로 분해
        components_a = self._extract_components(a)
        components_b = self._extract_components(b)
        
        if not components_a:
            return 0.0
        
        total_similarity = 0.0
        for c1 in components_a:
            max_sim = 0.0
            for c2 in components_b:
                sim_value = self.sim(c1, c2, depth)  # 재귀 호출 (깊이 전달)
                max_sim = max(max_sim, sim_value)
            total_similarity += max_sim
        
        # |Ca|로 나누어 평균 계산
        return total_similarity / len(components_a)
    
    def _extract_components(self, stmt: str) -> List[str]:
        """문장에서 구성 요소 추출"""
        # 라인별로 분할
        lines = [line.strip() for line in stmt.split('\n') if line.strip()]
        
        components = []
        for line in lines:
            # 세미콜론으로 분할된 문장들
            parts = [part.strip() for part in line.split(';') if part.strip()]
            components.extend(parts)
        
        return components
    
    def generate_similarity_based_patch(self, vulnerability: Dict[str, Any], 
                                      existing_code: str) -> Dict[str, Any]:
        """
        유사도 기반 패치 생성
        
        Args:
            vulnerability: 취약점 정보
            existing_code: 기존 코드
            
        Returns:
            Dict: 생성된 패치 정보
        """
        vuln_type = vulnerability.get('type', 'UNKNOWN')
        function_name = vulnerability.get('function', 'unknown')
        
        if vuln_type not in self.patch_templates:
            return self._generate_generic_patch(vulnerability, existing_code)
        
        # 템플릿 후보들과 기존 코드의 유사도 계산
        templates = self.patch_templates[vuln_type]
        best_template = self._select_best_template(templates, existing_code)
        
        # 패치 코드 생성
        patch_code = self._customize_template(best_template, vulnerability, existing_code)
        
        return {
            "vulnerability_id": f"{vulnerability.get('file', 'unknown')}#{function_name}",
            "patch_type": vuln_type,
            "patch_code": patch_code,
            "description": f"유사도 기반 패치 for {vuln_type} in {function_name}",
            "confidence": self._calculate_patch_confidence(best_template, existing_code),
            "similarity_score": self.sim(best_template, existing_code)
        }
    
    def _select_best_template(self, templates: List[str], existing_code: str) -> str:
        """기존 코드와 가장 유사한 템플릿 선택"""
        best_template = templates[0]
        best_similarity = 0.0
        
        for template in templates:
            similarity = self.sim(template, existing_code)
            if similarity > best_similarity:
                best_similarity = similarity
                best_template = template
        
        return best_template
    
    def _customize_template(self, template: str, vulnerability: Dict[str, Any], 
                          existing_code: str) -> str:
        """템플릿을 실제 코드에 맞게 커스터마이징"""
        # 함수 시그니처 추출
        function_info = vulnerability.get('hypothesis', {})
        function_name = vulnerability.get('function', 'method')
        
        # 매개변수 추출 (간단한 패턴 매칭)
        import re
        param_pattern = r'(\w+)\s+(\w+)[,\)]'
        params = re.findall(param_pattern, existing_code)
        
        # 템플릿 변수 치환
        customized = template
        if params:
            first_param = params[0][1] if len(params[0]) > 1 else 'param'
            first_type = params[0][0] if len(params[0]) > 0 else 'Object'
            
            customized = customized.replace('{param}', first_param)
            customized = customized.replace('{type}', first_type)
            customized = customized.replace('{expected_type}', first_type)
        
        # 전체 패치 코드 구성
        patch_code = f"""
// 유사도 기반 패치 (similarity score: {self.sim(template, existing_code):.2f})
public <T> T {function_name}(...) {{
    // 보안 검증 추가
    {customized}
    
    // 기존 코드...
}}
"""
        return patch_code
    
    def _calculate_patch_confidence(self, template: str, existing_code: str) -> float:
        """패치 신뢰도 계산"""
        similarity = self.sim(template, existing_code)
        
        # 유사도가 높을수록 신뢰도 증가
        base_confidence = 0.6
        similarity_bonus = similarity * 0.3
        
        return min(base_confidence + similarity_bonus, 0.95)
    
    def _generate_generic_patch(self, vulnerability: Dict[str, Any], 
                              existing_code: str) -> Dict[str, Any]:
        """일반적인 패치 생성 (fallback)"""
        function_name = vulnerability.get('function', 'method')
        
        return {
            "vulnerability_id": f"{vulnerability.get('file', 'unknown')}#{function_name}",
            "patch_type": "GENERIC",
            "patch_code": f"""
// 일반적인 보안 패치
public <T> T {function_name}(...) {{
    // TODO: 보안 검증 로직 추가 필요
    // 기존 코드...
}}
""",
            "description": f"일반적인 패치 for {function_name}",
            "confidence": 0.5,
            "similarity_score": 0.0
        }


class PatchValidator:
    """패치 적용 및 검증 엔진"""
    
    def __init__(self, vuln_id: int, logger):
        self.vuln_id = vuln_id
        self.logger = logger
        self.max_iterations = 10
        self.source_path = Path(f"./benchmark/Java/VUL4J/VUL4J-{vuln_id}")
        self.backup_path = Path(f"./backup/VUL4J-{vuln_id}")
        self.rule_dir = Path(f"./rule/VUL4J-{vuln_id}")
        
        # 백업 디렉토리 생성
        self.backup_path.mkdir(parents=True, exist_ok=True)
    
    def validate_and_refine_patches(self, vulnerabilities: List[Dict[str, Any]], 
                                  patches: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        패치를 적용하고 검증하여 취약점이 해결될 때까지 반복 개선
        
        Args:
            vulnerabilities: 탐지된 취약점 목록
            patches: 생성된 패치 목록
            
        Returns:
            List[Dict]: 검증된 패치 목록
        """
        validated_patches = []
        
        for i, patch in enumerate(patches):
            self.logger.info(f"=== 패치 검증 시작: {patch['vulnerability_id']} ===")
            
            # 원본 파일 백업
            self._backup_original_files()
            
            try:
                # 패치 적용 및 검증 반복
                validated_patch = self._iterative_patch_validation(
                    vulnerabilities[i] if i < len(vulnerabilities) else None,
                    patch
                )
                validated_patches.append(validated_patch)
                
            except Exception as e:
                self.logger.error(f"패치 검증 실패: {e}")
                # 실패한 패치도 결과에 포함 (상태 정보와 함께)
                patch['validation_status'] = 'failed'
                patch['validation_error'] = str(e)
                validated_patches.append(patch)
            
            finally:
                # 원본 파일 복원
                self._restore_original_files()
        
        return validated_patches
    
    def _iterative_patch_validation(self, vulnerability: Dict[str, Any], 
                                   patch: Dict[str, Any]) -> Dict[str, Any]:
        """반복적 패치 적용 및 검증 - LLM이 5개씩 새로운 패치 생성"""
        current_patches = [patch]  # 초기 패치 목록
        
        for iteration in range(1, self.max_iterations + 1):
            self.logger.info(f"패치 검증 반복 {iteration}/{self.max_iterations}")
            
            # 현재 패치들 중에서 최적 패치 선택
            if len(current_patches) > 1:
                # 원본 코드 읽기
                file_path = self.source_path / vulnerability['file']
                original_code = ""
                if file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        original_code = f.read()
                
                # 유사도 기반 최적 패치 선택
                selected_patch = self._select_best_patch_from_candidates(current_patches, original_code)
            else:
                selected_patch = current_patches[0]
            
            if not selected_patch:
                self.logger.error(f"선택할 패치가 없습니다 - 반복 {iteration}")
                break
            
            # 패치 적용
            patched_file_path = self._apply_patch(selected_patch)
            
            if not patched_file_path:
                self.logger.error(f"패치 적용 실패 - 반복 {iteration}")
                selected_patch['validation_status'] = 'apply_failed'
                selected_patch['validation_iterations'] = iteration
                break
            
            # 정적 분석 도구로 검증
            validation_result = self._validate_with_static_analysis(
                vulnerability, patched_file_path
            )
            
            if validation_result['is_vulnerable']:
                self.logger.warning(f"반복 {iteration}: 여전히 취약점 탐지됨")
                
                # 새로운 패치들 생성 (LLM으로 5개)
                if iteration < self.max_iterations:
                    self.logger.info(f"새로운 5개 패치 생성 중... (반복 {iteration + 1})")
                    
                    # LLM으로 새로운 5개 패치 생성
                    new_patches = self._generate_new_patches_for_validation(
                        vulnerability, validation_result, iteration
                    )
                    
                    if new_patches:
                        current_patches = new_patches
                        self.logger.info(f"새로운 {len(new_patches)}개 패치 생성됨")
                    else:
                        self.logger.error("새로운 패치 생성 실패")
                        selected_patch['validation_status'] = 'patch_generation_failed'
                        selected_patch['validation_iterations'] = iteration
                        selected_patch['final_validation_result'] = validation_result
                        break
                else:
                    self.logger.error(f"최대 반복 횟수 도달 - 패치 검증 실패")
                    selected_patch['validation_status'] = 'max_iterations_reached'
                    selected_patch['validation_iterations'] = iteration
                    selected_patch['final_validation_result'] = validation_result
                    break
            else:
                self.logger.info(f"✅ 패치 검증 성공! (반복 {iteration})")
                selected_patch['validation_status'] = 'success'
                selected_patch['validation_iterations'] = iteration
                selected_patch['final_validation_result'] = validation_result
                break
        
        return selected_patch
    
    def _select_best_patch_from_candidates(self, patches, original_code):
        """후보 패치들 중에서 유사도 기반으로 최적 패치 선택"""
        if not patches:
            return None
        
        best_patch = None
        best_similarity = -1
        
        for patch in patches:
            try:
                # 패치 적용된 코드 시뮬레이션
                patched_code = self._simulate_patch_for_validation(original_code, patch["patch_code"])
                
                # 간단한 유사도 계산 (Levenshtein distance 기반)
                similarity = self._calculate_simple_similarity(original_code, patched_code)
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_patch = patch
                    
            except Exception as e:
                self.logger.error(f"패치 유사도 계산 실패: {e}")
                continue
        
        return best_patch
    
    def _generate_new_patches_for_validation(self, vulnerability, validation_result, iteration):
        """검증 실패 시 새로운 5개 패치 생성"""
        try:
            # 실패 정보를 바탕으로 개선된 프롬프트 생성
            vuln_types = [v["type"] for v in vulnerability["hypothesis"]["vulnerabilities"]]
            primary_vuln = vuln_types[0] if vuln_types else "UNKNOWN"
            
            # 실패 원인 분석
            failure_info = ""
            if validation_result.get('semgrep_findings'):
                failure_info += f"Semgrep 탐지: {len(validation_result['semgrep_findings'])}개 발견\n"
            if validation_result.get('codeql_findings'):
                failure_info += f"CodeQL 탐지: {len(validation_result['codeql_findings'])}개 발견\n"
            
            # 개선된 프롬프트
            prompt = f"""
이전 패치가 검증에 실패했습니다. 더 강력한 5개의 보안 패치를 생성해주세요.

파일: {vulnerability['file']}
함수: {vulnerability['function']}
취약점 유형: {', '.join(vuln_types)}
반복 횟수: {iteration + 1}/10

실패 원인:
{failure_info}

요구사항:
1. 이전보다 더 강력한 보안 검증 추가
2. 각 패치는 서로 다른 방어 전략 사용
3. 실제 적용 가능한 Java 코드로 작성
4. null 검증, 타입 검증, 입력 검증 등 포함

응답 형식:
PATCH_1:
[더 강력한 Java 보안 코드]
설명: [패치 설명]

PATCH_2:
[더 강력한 Java 보안 코드]
설명: [패치 설명]

PATCH_3:
[더 강력한 Java 보안 코드]
설명: [패치 설명]

PATCH_4:
[더 강력한 Java 보안 코드]
설명: [패치 설명]

PATCH_5:
[더 강력한 Java 보안 코드]
설명: [패치 설명]
"""
            
            # LLM에서 새로운 패치들 생성 (여기서는 간단한 시뮬레이션)
            # 실제로는 LLM 인터페이스를 통해 호출해야 함
            new_patches = self._generate_enhanced_patches(vulnerability, iteration)
            
            return new_patches
            
        except Exception as e:
            self.logger.error(f"새로운 패치 생성 실패: {e}")
            return []
    
    def _generate_enhanced_patches(self, vulnerability, iteration):
        """강화된 패치들 생성 (LLM 대신 템플릿 기반)"""
        patches = []
        function_name = vulnerability['function']
        
        # 반복 횟수에 따라 점진적으로 강화된 패치 생성
        enhanced_templates = [
            f"""
// 강화된 패치 #{iteration}-1: Null 검증 강화
if (parser == null) {{
    throw new IllegalArgumentException("Parser cannot be null");
}}
if (type == null) {{
    throw new IllegalArgumentException("Type cannot be null");
}}
Objects.requireNonNull(fieldName, "Field name cannot be null");
""",
            f"""
// 강화된 패치 #{iteration}-2: 타입 안전성 검증
if (!(type instanceof Class) && !(type instanceof GenericArrayType)) {{
    throw new IllegalArgumentException("Invalid type: " + type);
}}
SecurityManager sm = System.getSecurityManager();
if (sm != null) {{
    sm.checkPermission(new RuntimePermission("deserialize"));
}}
""",
            f"""
// 강화된 패치 #{iteration}-3: 입력 검증 및 제한
if (parser.lexer.token() == JSONToken.ERROR) {{
    throw new JSONException("Invalid JSON token");
}}
// 배열 크기 제한
final int MAX_ARRAY_SIZE = 10000;
if (array != null && array.size() > MAX_ARRAY_SIZE) {{
    throw new JSONException("Array size exceeds limit: " + array.size());
}}
""",
            f"""
// 강화된 패치 #{iteration}-4: 재귀 깊이 제한
ThreadLocal<Integer> recursionDepth = new ThreadLocal<Integer>() {{
    @Override
    protected Integer initialValue() {{
        return 0;
    }}
}};
int currentDepth = recursionDepth.get();
if (currentDepth > 100) {{
    throw new JSONException("Maximum recursion depth exceeded");
}}
recursionDepth.set(currentDepth + 1);
""",
            f"""
// 강화된 패치 #{iteration}-5: 종합 보안 검증
// 모든 입력 검증
Objects.requireNonNull(parser, "Parser required");
Objects.requireNonNull(type, "Type required");
// 보안 정책 확인
if (System.getProperty("json.security.enabled", "true").equals("true")) {{
    // 추가 보안 검증 로직
    validateSecurityConstraints(parser, type, fieldName);
}}
"""
        ]
        
        for i, template in enumerate(enhanced_templates, 1):
            patch = {
                "vulnerability_id": f"{vulnerability['file']}#{function_name}",
                "patch_type": "ENHANCED_SECURITY",
                "patch_code": template,
                "description": f"강화된 보안 패치 #{iteration}-{i}",
                "confidence": 0.9,
                "method": f"enhanced_template_{iteration}_{i}",
                "iteration": iteration
            }
            patches.append(patch)
        
        return patches
    
    def _simulate_patch_for_validation(self, original_code, patch_code):
        """검증용 패치 적용 시뮬레이션"""
        if not patch_code.strip():
            return original_code
        
        # 간단한 패치 적용 시뮬레이션
        return original_code + "\n" + patch_code
    
    def _calculate_simple_similarity(self, code1, code2):
        """간단한 유사도 계산"""
        if not code1 or not code2:
            return 0.0
        
        # Levenshtein distance 기반 유사도
        len1, len2 = len(code1), len(code2)
        if len1 == 0:
            return 0.0 if len2 > 0 else 1.0
        if len2 == 0:
            return 0.0
        
        # 간단한 문자 기반 유사도
        common_chars = len(set(code1) & set(code2))
        total_chars = len(set(code1) | set(code2))
        
        return common_chars / total_chars if total_chars > 0 else 0.0
    
    def _apply_patch(self, patch: Dict[str, Any]) -> Optional[Path]:
        """
        패치를 실제 파일에 적용
        
        Args:
            patch: 적용할 패치 정보
            
        Returns:
            Optional[Path]: 패치가 적용된 파일 경로
        """
        try:
            # 패치 대상 파일 식별
            vulnerability_id = patch['vulnerability_id']
            file_name = vulnerability_id.split('#')[0]
            file_path = self.source_path / file_name
            
            if not file_path.exists():
                self.logger.error(f"패치 대상 파일 없음: {file_path}")
                return None
            
            # 원본 파일 읽기
            with open(file_path, 'r', encoding='utf-8') as f:
                original_content = f.read()
            
            # 패치 적용
            patched_content = self._merge_patch_with_original(
                original_content, patch
            )
            
            # 패치된 내용 저장
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(patched_content)
            
            self.logger.info(f"패치 적용 완료: {file_path}")
            return file_path
            
        except Exception as e:
            self.logger.error(f"패치 적용 중 오류: {e}")
            return None
    
    def _merge_patch_with_original(self, original_content: str, 
                                  patch: Dict[str, Any]) -> str:
        """
        원본 코드와 패치를 병합
        
        Args:
            original_content: 원본 파일 내용
            patch: 패치 정보
            
        Returns:
            str: 패치가 적용된 코드
        """
        # 함수명 추출
        function_name = patch['vulnerability_id'].split('#')[1]
        patch_code = patch['patch_code']
        
        # 패치 코드에서 실제 보안 검증 코드 추출
        security_checks = self._extract_security_checks(patch_code)
        
        # 원본 코드에서 해당 함수 찾기 및 패치 적용
        patched_content = self._inject_security_checks(
            original_content, function_name, security_checks
        )
        
        return patched_content
    
    def _extract_security_checks(self, patch_code: str) -> List[str]:
        """패치 코드에서 보안 검증 코드 추출"""
        security_checks = []
        
        # 패치 코드에서 보안 검증 라인들 추출
        lines = patch_code.split('\n')
        for line in lines:
            line = line.strip()
            if (line.startswith('if (') and 
                ('null' in line or 'Valid' in line or 'Security' in line)):
                security_checks.append(line)
            elif line.startswith('Objects.requireNonNull'):
                security_checks.append(line)
            elif line.startswith('validate') and line.endswith(';'):
                security_checks.append(line)
        
        return security_checks
    
    def _inject_security_checks(self, original_content: str, 
                               function_name: str, 
                               security_checks: List[str]) -> str:
        """원본 코드의 함수에 보안 검증 코드 삽입"""
        if not security_checks:
            return original_content
        
        # 함수 시작 부분 찾기
        pattern = rf'(public\s+.*?\s+{re.escape(function_name)}\s*\([^)]*\)\s*\{{)'
        match = re.search(pattern, original_content, re.MULTILINE | re.DOTALL)
        
        if not match:
            self.logger.warning(f"함수 {function_name}을 찾을 수 없음")
            return original_content
        
        # 함수 시작 후 보안 검증 코드 삽입
        function_start = match.end()
        
        # 보안 검증 코드 포맷팅
        security_section = '\n        // 보안 검증 추가\n'
        for check in security_checks:
            security_section += f'        {check}\n'
        security_section += '\n'
        
        # 코드 삽입
        patched_content = (
            original_content[:function_start] + 
            security_section + 
            original_content[function_start:]
        )
        
        return patched_content
    
    def _validate_with_static_analysis(self, vulnerability: Dict[str, Any], 
                                     patched_file_path: Path) -> Dict[str, Any]:
        """
        정적 분석 도구로 패치 검증
        
        Args:
            vulnerability: 취약점 정보
            patched_file_path: 패치된 파일 경로
            
        Returns:
            Dict: 검증 결과
        """
        validation_result = {
            'is_vulnerable': False,
            'semgrep_findings': [],
            'codeql_findings': [],
            'tools_used': []
        }
        
        # Semgrep 검증
        if vulnerability and 'semgrep_rule' in vulnerability:
            semgrep_result = self._run_semgrep_validation(
                vulnerability, patched_file_path
            )
            validation_result['semgrep_findings'] = semgrep_result.get('findings', [])
            validation_result['tools_used'].append('semgrep')
            
            if semgrep_result.get('findings'):
                validation_result['is_vulnerable'] = True
        
        # CodeQL 검증
        if vulnerability and 'codeql_rule' in vulnerability:
            codeql_result = self._run_codeql_validation(
                vulnerability, patched_file_path
            )
            validation_result['codeql_findings'] = codeql_result.get('findings', [])
            validation_result['tools_used'].append('codeql')
            
            if codeql_result.get('findings'):
                validation_result['is_vulnerable'] = True
        
        return validation_result
    
    def _run_semgrep_validation(self, vulnerability: Dict[str, Any], 
                               file_path: Path) -> Dict[str, Any]:
        """Semgrep으로 패치 검증"""
        try:
            function_name = vulnerability['function']
            rule_file = self.rule_dir / f"semgrep{self.vuln_id}-{function_name}"
            
            if not rule_file.exists():
                return {'status': 'no_rule', 'findings': []}
            
            # Semgrep 실행
            cmd = [
                'semgrep', 
                '--config', str(rule_file),
                '--json',
                str(file_path)
            ]
            
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=30,
                env=dict(os.environ, PATH=os.environ['PATH'] + ':' + str(Path.home() / '.local/bin'))
            )
            
            if result.returncode == 0:
                output = json.loads(result.stdout)
                findings = output.get('results', [])
                
                self.logger.info(f"Semgrep 검증: {len(findings)}개 발견")
                return {'status': 'success', 'findings': findings}
            else:
                self.logger.warning(f"Semgrep 검증 오류: {result.stderr}")
                return {'status': 'error', 'findings': []}
                
        except Exception as e:
            self.logger.error(f"Semgrep 검증 실패: {e}")
            return {'status': 'error', 'findings': []}
    
    def _run_codeql_validation(self, vulnerability: Dict[str, Any], 
                              file_path: Path) -> Dict[str, Any]:
        """CodeQL로 패치 검증"""
        try:
            function_name = vulnerability['function']
            rule_file = self.rule_dir / f"codeql{self.vuln_id}-{function_name}"
            
            if not rule_file.exists():
                return {'status': 'no_rule', 'findings': []}
            
            # CodeQL 데이터베이스 생성 및 실행
            db_path = f"codeql_db_validation_{self.vuln_id}"
            
            # 기존 DB 삭제
            if os.path.exists(db_path):
                shutil.rmtree(db_path)
            
            # DB 생성
            create_cmd = [
                'codeql', 'database', 'create', db_path,
                '--language=java',
                f'--source-root={file_path.parent}'
            ]
            
            create_result = subprocess.run(
                create_cmd, 
                capture_output=True, 
                text=True, 
                timeout=60
            )
            
            if create_result.returncode != 0:
                self.logger.warning(f"CodeQL DB 생성 실패: {create_result.stderr}")
                return {'status': 'db_creation_failed', 'findings': []}
            
            # 쿼리 실행
            query_cmd = [
                'codeql', 'database', 'analyze', db_path,
                str(rule_file),
                '--format=csv',
                '--output=codeql_results.csv'
            ]
            
            query_result = subprocess.run(
                query_cmd, 
                capture_output=True, 
                text=True, 
                timeout=60
            )
            
            findings = []
            if query_result.returncode == 0 and os.path.exists('codeql_results.csv'):
                with open('codeql_results.csv', 'r') as f:
                    csv_content = f.read()
                    findings = csv_content.strip().split('\n')[1:]  # 헤더 제외
            
            # 정리
            if os.path.exists(db_path):
                shutil.rmtree(db_path)
            if os.path.exists('codeql_results.csv'):
                os.remove('codeql_results.csv')
            
            self.logger.info(f"CodeQL 검증: {len(findings)}개 발견")
            return {'status': 'success', 'findings': findings}
            
        except Exception as e:
            self.logger.error(f"CodeQL 검증 실패: {e}")
            return {'status': 'error', 'findings': []}
    
    def _improve_patch(self, current_patch: Dict[str, Any], 
                      validation_result: Dict[str, Any], 
                      iteration: int) -> Dict[str, Any]:
        """
        검증 결과를 바탕으로 패치 개선
        
        Args:
            current_patch: 현재 패치
            validation_result: 검증 결과
            iteration: 현재 반복 횟수
            
        Returns:
            Dict: 개선된 패치
        """
        self.logger.info(f"패치 개선 중 - 반복 {iteration}")
        
        improved_patch = current_patch.copy()
        
        # 추가 보안 검증 로직 생성
        additional_checks = []
        
        # Semgrep 결과 분석
        if validation_result.get('semgrep_findings'):
            for finding in validation_result['semgrep_findings']:
                if 'parseArray' in str(finding):
                    additional_checks.append(
                        'if (componentType == null) { throw new IllegalArgumentException("ComponentType cannot be null"); }'
                    )
                    additional_checks.append(
                        'if (array == null) { throw new IllegalArgumentException("Array cannot be null"); }'
                    )
        
        # CodeQL 결과 분석
        if validation_result.get('codeql_findings'):
            additional_checks.append(
                'validateInputSafety(parser, type, fieldName);'
            )
        
        # 일반적인 강화 (반복 횟수에 따라)
        if iteration >= 3:
            additional_checks.extend([
                'if (fieldName != null && fieldName.toString().contains("unsafe")) { throw new SecurityException("Unsafe field detected"); }',
                'SecurityManager.checkPermission(new RuntimePermission("deserialize"));'
            ])
        
        if iteration >= 5:
            additional_checks.extend([
                'if (System.getProperty("security.strict", "false").equals("true")) { throw new SecurityException("Strict security mode enabled"); }',
                'auditLog("Deserialization attempt", parser, type, fieldName);'
            ])
        
        # 패치 코드 업데이트
        if additional_checks:
            original_patch_code = improved_patch['patch_code']
            
            # 추가 보안 검증을 패치 코드에 삽입
            security_section = '\n        // 추가 보안 검증 (반복 ' + str(iteration) + ')\n'
            for check in additional_checks:
                security_section += f'        {check}\n'
            
            # 기존 패치 코드에 추가
            if '// 보안 검증 추가' in original_patch_code:
                improved_patch_code = original_patch_code.replace(
                    '// 보안 검증 추가',
                    '// 보안 검증 추가' + security_section
                )
            else:
                # 함수 시작 부분에 추가
                lines = original_patch_code.split('\n')
                for i, line in enumerate(lines):
                    if '{' in line and 'public' in lines[max(0, i-2):i+1]:
                        lines.insert(i+1, security_section)
                        break
                improved_patch_code = '\n'.join(lines)
            
            improved_patch['patch_code'] = improved_patch_code
            improved_patch['improvement_iteration'] = iteration
            improved_patch['additional_checks'] = additional_checks
        
        return improved_patch
    
    def _backup_original_files(self):
        """원본 파일들을 백업"""
        try:
            if self.backup_path.exists():
                shutil.rmtree(self.backup_path)
            
            shutil.copytree(self.source_path, self.backup_path)
            self.logger.info(f"원본 파일 백업 완료: {self.backup_path}")
            
        except Exception as e:
            self.logger.error(f"파일 백업 실패: {e}")
    
    def _restore_original_files(self):
        """백업된 원본 파일들을 복원"""
        try:
            if not self.backup_path.exists():
                self.logger.warning("백업 파일이 존재하지 않음")
                return
            
            # 기존 파일 삭제
            if self.source_path.exists():
                shutil.rmtree(self.source_path)
            
            # 백업에서 복원
            shutil.copytree(self.backup_path, self.source_path)
            self.logger.info(f"원본 파일 복원 완료: {self.source_path}")
            
        except Exception as e:
            self.logger.error(f"파일 복원 실패: {e}")


class AdvancedVulnerabilityAnalyzer:
    def __init__(self, vuln_id: int, llm_interface=None):
        self.vuln_id = vuln_id
        
        # LLM 설정 로드 (로깅 초기화 전에 수행)
        self.llm_config = self._load_llm_config(llm_interface)
        self.llm = self._initialize_llm()
        
        # LLM 모델 이름 추출
        self.llm_model_name = self._get_llm_model_name()
        
        # 로깅 시스템 초기화 (모델별)
        self.logger = setup_logging(self.llm_model_name)
        
        self.source_path = Path(f"./benchmark/Java/VUL4J/VUL4J-{vuln_id}")
        self.target_path = self.source_path  # 정적 분석 대상 경로
        
        # 모델별 규칙 및 로그 디렉토리 생성
        self.rule_dir = Path(f"./rule/VUL4J-{vuln_id}/{self.llm_model_name}")
        self.log_dir = Path(f"./log/{self.llm_model_name}/VUL4J-{vuln_id}")
        self.analysis_dir = self.log_dir / "analysis"
        
        # 디렉토리 생성
        self.rule_dir.mkdir(parents=True, exist_ok=True)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        self.analysis_dir.mkdir(parents=True, exist_ok=True)
        
        # 단계별 처리기 초기화
        self.ast_processor = ASTProcessor()
        self.vulnerability_detector = VulnerabilityDetector(self.llm)
        self.patch_generator = PatchGenerator(self.llm)
        self.patch_similarity_engine = PatchSimilarityEngine()
        self.patch_validator = PatchValidator(vuln_id, self.logger)
        
        self.logger.info(f"취약점 분석기 초기화 완료 - ID: {vuln_id}, Model: {self.llm_model_name}")
        if self.llm:
            self.logger.info(f"LLM 연결됨: {self.llm.__class__.__name__}")
    
    def _get_llm_model_name(self) -> str:
        """LLM 모델 이름 추출"""
        if self.llm:
            if hasattr(self.llm, 'model'):
                # 모델명에서 특수문자 제거하여 디렉토리명으로 사용 가능하게 변환
                model_name = str(self.llm.model).replace(':', '_').replace('/', '_').replace('.', '_')
                return model_name
            else:
                return self.llm.__class__.__name__.lower().replace('interface', '')
        return "pattern_matching"
    
    def _load_llm_config(self, llm_interface: Optional[LLMInterface]) -> Dict[str, Any]:
        """LLM 설정 로드 - 직접 전달된 LLM 인터페이스 우선 처리"""
        # 직접 전달된 LLM 인터페이스가 있으면 그것을 사용하기 위한 설정 반환
        if llm_interface:
            return {
                "type": "direct_interface",
                "interface": llm_interface
            }
        
        # llm_config.json 파일에서 설정 로드
        config_file = Path("llm_config.json")
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                # provider 기반 설정 구조 지원
                if "provider" in config_data:
                    provider = config_data["provider"]
                    if provider in config_data:
                        provider_config = config_data[provider].copy()
                        provider_config["type"] = provider
                        return provider_config
                
                # 기존 llm_configs 구조 지원
                for llm_cfg in config_data.get("llm_configs", []):
                    if llm_cfg.get("enabled", False):
                        return llm_cfg
                
                # 기본 LLM 사용
                default_llm_name = config_data.get("default_llm", "gemini")
                for llm_cfg in config_data.get("llm_configs", []):
                    if llm_cfg.get("name") == default_llm_name:
                        return llm_cfg
                        
            except Exception as e:
                if hasattr(self, 'logger'):
                    self.logger.warning(f"LLM 설정 로드 실패: {str(e)}")
        
        # 기본 설정 반환 (Gemini)
        return {
            "type": "gemini",
            "model": "gemini-1.5-flash", 
            "api_key": "",
            "temperature": 0.1
        }
    
    def _initialize_llm(self) -> Optional[LLMInterface]:
        """LLM 초기화"""
        try:
            # 직접 전달된 인터페이스가 있으면 그것을 사용
            if self.llm_config.get("type") == "direct_interface":
                return self.llm_config.get("interface")
            
            # 일반적인 LLM 팩토리를 통한 생성
            llm_type = self.llm_config.get("type", "gemini")
            return LLMFactory.create_llm(llm_type, **self.llm_config)
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.warning(f"LLM 초기화 실패: {str(e)}")
                self.logger.info("패턴 매칭 방식으로 대체")
            return None
    
    def analyze(self) -> Dict[str, Any]:
        """전체 분석 프로세스 실행"""
        try:
            self.logger.info("=== Stage 1: 사전 작업 시작 ===")
            ast_data = self.stage1_preprocessing()
            
            self.logger.info("=== Stage 2: 취약점 분석 시작 ===")
            vulnerabilities = self.stage2_vulnerability_analysis(ast_data)
            
            self.logger.info("=== Stage 3: 패치 생성 시작 ===")
            patches = self._generate_patches(vulnerabilities)
            
            self.logger.info("=== Stage 4: 패치 검증 및 개선 시작 ===")
            validated_patches = self.patch_validator.validate_and_refine_patches(
                vulnerabilities, patches
            )
            
            result = {
                "vuln_id": self.vuln_id,
                "timestamp": datetime.now().isoformat(),
                "ast_data": ast_data,
                "vulnerabilities": vulnerabilities,
                "patches": patches,
                "validated_patches": validated_patches,
                "status": "completed"
            }
            
            # 결과 저장
            self._save_analysis_result(result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"분석 중 오류 발생: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def stage1_preprocessing(self) -> Dict[str, Any]:
        """Stage 1: AST 노드 추출 및 함수/클래스 단위 분리"""
        self.logger.info("AST 노드 추출 시작")
        
        java_files = list(self.source_path.glob("*.java"))
        if not java_files:
            raise FileNotFoundError(f"Java 파일을 찾을 수 없습니다: {self.source_path}")
        
        ast_data = {}
        for java_file in java_files:
            self.logger.info(f"파일 처리 중: {java_file.name}")
            file_ast = self.ast_processor.extract_ast(java_file)
            ast_data[java_file.name] = file_ast
        
        self.logger.info(f"AST 추출 완료 - {len(ast_data)} 파일 처리")
        return ast_data
    
    def stage2_vulnerability_analysis(self, ast_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Stage 2: 취약점 분석"""
        vulnerabilities = []
        
        for file_name, file_ast in ast_data.items():
            self.logger.info(f"취약점 분석 중: {file_name}")
            
            # 각 함수에 대해 취약점 분석
            for func_info in file_ast.get("functions", []):
                func_name = func_info["name"]
                
                # LLM 취약점 가설 생성
                hypothesis = self.vulnerability_detector.generate_hypothesis(func_info)
                
                if hypothesis:
                    # Semgrep 및 CodeQL 규칙 생성
                    semgrep_rule = self.vulnerability_detector.generate_semgrep_rule(
                        self.vuln_id, func_name, hypothesis
                    )
                    codeql_rule = self.vulnerability_detector.generate_codeql_rule(
                        self.vuln_id, func_name, hypothesis
                    )
                    
                    # 규칙 저장
                    semgrep_rule_file = self._save_rule("semgrep", self.vuln_id, func_name, semgrep_rule)
                    codeql_rule_file = self._save_rule("codeql", self.vuln_id, func_name, codeql_rule)
                    
                    # 실제 정적 분석 도구 실행
                    semgrep_results = None
                    codeql_results = None
                    
                    # Semgrep 비활성화 - CodeQL만 사용  
                    # if semgrep_rule_file and semgrep_rule.strip():
                    #     self.logger.info(f"Semgrep 실행 중: {func_name}")
                    #     semgrep_results = self.vulnerability_detector.run_semgrep_analysis(
                    #         str(semgrep_rule_file), 
                    #         str(self.target_path)
                    #     )
                    self.logger.info(f"Semgrep 비활성화됨 - CodeQL만 사용")
                    
                    if codeql_rule_file and codeql_rule.strip():
                        self.logger.info(f"CodeQL 실행 중: {func_name}")
                        codeql_results = self.vulnerability_detector.run_codeql_analysis(
                            str(codeql_rule_file),
                            str(self.target_path)
                        )
                    
                    confirmed = self._is_vulnerability_confirmed(semgrep_results, codeql_results)
                    
                    vulnerability = {
                        "file": file_name,
                        "function": func_name,
                        "hypothesis": hypothesis,
                        "semgrep_rule": semgrep_rule,
                        "codeql_rule": codeql_rule,
                        "severity": hypothesis.get("severity", "medium"),
                        "semgrep_results": semgrep_results,
                        "codeql_results": codeql_results,
                        "confirmed": confirmed
                    }
                    
                    # 검증된 취약점만 결과에 포함 (개발/테스트시에는 모두 포함)
                    vulnerabilities.append(vulnerability)
        
        self.logger.info(f"취약점 분석 완료 - {len(vulnerabilities)}개 발견")
        return vulnerabilities
    
    def _generate_patches(self, vulnerabilities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """패치 생성 - confidence 기반 정렬 및 개별 취약점별 5개 패치 생성"""
        self.logger.info("=== Stage 3: 패치 생성 시작 ===")
        
        # 1. Confidence 기반 내림차순 정렬
        sorted_vulnerabilities = self._sort_vulnerabilities_by_confidence(vulnerabilities)
        
        all_patches = []
        
        for vuln in sorted_vulnerabilities:
            self.logger.info(f"패치 생성 중: {vuln['file']}#{vuln['function']}")
            self.logger.info(f"취약점 confidence: {vuln.get('hypothesis', {}).get('confidence', 'unknown')}")
            
            # 2. 각 취약점별로 5개 패치 생성
            patches = self._generate_patches_for_vulnerability(vuln, count=5)
            
            # 3. 유사도 기반 최적 패치 선택
            if patches:
                best_patch = self._select_best_patch_by_similarity(patches, vuln.get('implementation', ''))
                if best_patch:
                    all_patches.append(best_patch)
                    
                # 템플릿 기반 백업 패치도 생성
                template_patch = self._generate_template_patch(vuln)
                if template_patch:
                    all_patches.append(template_patch)
        
        self.logger.info(f"패치 생성 완료 - {len(all_patches)}개 생성")
        return all_patches
    
    def _sort_vulnerabilities_by_confidence(self, vulnerabilities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """취약점을 confidence 기준으로 내림차순 정렬"""
        def get_confidence(vuln):
            hypothesis = vuln.get('hypothesis', {})
            confidence = hypothesis.get('confidence', 0)
            
            # confidence가 문자열인 경우 숫자로 변환
            if isinstance(confidence, str):
                try:
                    confidence = float(confidence)
                except:
                    confidence = 0.5  # 기본값
            
            return confidence
        
        sorted_vulns = sorted(vulnerabilities, key=get_confidence, reverse=True)
        
        self.logger.info("=== 취약점 Confidence 기반 정렬 ===")
        for i, vuln in enumerate(sorted_vulns, 1):
            confidence = get_confidence(vuln)
            vuln_type = vuln.get('hypothesis', {}).get('vulnerabilities', [{}])[0].get('type', 'Unknown')
            self.logger.info(f"{i}. {vuln['function']} - {vuln_type} (confidence: {confidence:.2f})")
        
        return sorted_vulns
    
    def _generate_patches_for_vulnerability(self, vulnerability: Dict[str, Any], count: int = 5) -> List[Dict[str, Any]]:
        """개별 취약점에 대해 지정된 개수의 패치 생성"""
        patches = []
        
        # LLM 배치 패치 생성
        llm_patches = self._generate_llm_patches_batch(vulnerability, count)
        if llm_patches:
            patches.extend(llm_patches)
        
        # 부족한 경우 템플릿 기반 패치 추가 생성
        while len(patches) < count:
            template_patch = self._generate_template_patch(vulnerability)
            if template_patch:
                patches.append(template_patch)
            else:
                break
        
        self.logger.info(f"취약점 {vulnerability['function']}에 대해 {len(patches)}개 패치 생성")
        return patches[:count]  # 정확히 count 개수만 반환
    
    def _generate_llm_patches_batch(self, vuln_data, count=5):
        """LLM을 사용하여 여러 개의 패치를 한 번에 생성"""
        patches = []
        
        try:
            # 취약점 정보 준비
            vuln_types = [v["type"] for v in vuln_data["hypothesis"]["vulnerabilities"]]
            primary_vuln = vuln_types[0] if vuln_types else "UNKNOWN"
            
            # LLM 프롬프트 - 5개 패치 생성 요청
            prompt = f"""
다음 Java 코드의 {primary_vuln} 취약점에 대해 5개의 서로 다른 보안 패치를 생성해주세요.

파일: {vuln_data['file']}
함수: {vuln_data['function']}
취약점 유형: {', '.join(vuln_types)}

요구사항:
1. 각 패치는 서로 다른 접근 방식을 사용해야 함
2. 보안성과 기능성을 모두 고려해야 함
3. 실제 적용 가능한 Java 코드로 작성
4. 각 패치에 간단한 설명 포함

응답 형식:
PATCH_1:
[Java 코드]
설명: [패치 설명]

PATCH_2:
[Java 코드]
설명: [패치 설명]

PATCH_3:
[Java 코드]
설명: [패치 설명]

PATCH_4:
[Java 코드]
설명: [패치 설명]

PATCH_5:
[Java 코드]
설명: [패치 설명]
"""
            
            response = self.llm.generate_response(prompt)
            
            if response:
                # 응답에서 패치들 파싱
                parsed_patches = self._parse_llm_batch_response(response, vuln_data)
                patches.extend(parsed_patches)
                
                self.logger.info(f"LLM 배치 패치 생성 완료: {len(parsed_patches)}개")
            
        except Exception as e:
            self.logger.error(f"LLM 배치 패치 생성 실패: {e}")
        
        return patches
    
    def _parse_llm_batch_response(self, response, vuln_data):
        """LLM 배치 응답에서 개별 패치들 파싱"""
        patches = []
        
        try:
            # PATCH_N: 패턴으로 분할
            import re
            patch_sections = re.split(r'PATCH_\d+:', response)
            
            for i, section in enumerate(patch_sections[1:], 1):  # PATCH_1부터 시작
                if section.strip():
                    # 코드와 설명 분리
                    lines = section.strip().split('\n')
                    code_lines = []
                    description = f"LLM 생성 패치 #{i}"
                    
                    for line in lines:
                        if line.strip().startswith('설명:'):
                            description = line.replace('설명:', '').strip()
                        elif not line.strip().startswith('설명:') and line.strip():
                            code_lines.append(line)
                    
                    patch_code = '\n'.join(code_lines).strip()
                    
                    if patch_code:
                        vuln_types = [v["type"] for v in vuln_data["hypothesis"]["vulnerabilities"]]
                        primary_vuln = vuln_types[0] if vuln_types else "UNKNOWN"
                        
                        patch = {
                            "vulnerability_id": f"{vuln_data['file']}#{vuln_data['function']}",
                            "patch_type": primary_vuln,
                            "patch_code": patch_code,
                            "description": description,
                            "confidence": 0.8,
                            "method": f"llm_batch_{i}",
                            "batch_index": i
                        }
                        patches.append(patch)
            
        except Exception as e:
            self.logger.error(f"LLM 배치 응답 파싱 실패: {e}")
        
        return patches
    
    def _select_best_patch_by_similarity(self, patches, original_code):
        """유사도 알고리즘을 사용하여 최적 패치 선택"""
        if not patches:
            return None
        
        best_patch = None
        best_similarity = -1
        
        self.logger.info(f"유사도 기반 패치 선택 시작: {len(patches)}개 후보")
        
        for patch in patches:
            try:
                # 패치 적용된 코드 시뮬레이션
                patched_code = self._simulate_patch_application(original_code, patch["patch_code"])
                
                # 유사도 계산
                similarity = self.patch_similarity_engine.sim(original_code, patched_code)
                
                self.logger.info(f"패치 '{patch.get('method', 'unknown')}' 유사도: {similarity:.4f}")
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_patch = patch
                    best_patch["similarity_score"] = similarity
                    
            except Exception as e:
                self.logger.error(f"패치 유사도 계산 실패: {e}")
                continue
        
        if best_patch:
            self.logger.info(f"선택된 최적 패치: {best_patch.get('method', 'unknown')} (유사도: {best_similarity:.4f})")
        
        return best_patch
    
    def _simulate_patch_application(self, original_code, patch_code):
        """패치 적용 시뮬레이션 (실제 적용 전 테스트)"""
        if not patch_code.strip():
            return original_code
        
        # 함수 시작 부분에 보안 검증 코드 삽입하는 방식으로 시뮬레이션
        lines = original_code.split('\n')
        patched_lines = []
        
        for line in lines:
            patched_lines.append(line)
            # 함수 시작 후 첫 번째 실행 라인에 패치 코드 삽입
            if '{' in line and any(keyword in line for keyword in ['public', 'private', 'protected']):
                # 패치 코드를 다음 라인에 삽입
                for patch_line in patch_code.split('\n'):
                    if patch_line.strip():
                        patched_lines.append('    ' + patch_line.strip())
        
        return '\n'.join(patched_lines)
    
    def _generate_llm_patch(self, vuln: Dict[str, Any]) -> Dict[str, Any]:
        """기존 LLM 기반 패치 생성 (기존 로직 유지)"""
        try:
            # ... existing LLM patch generation logic ...
            function_name = vuln.get('function', 'method')
            vuln_type = vuln['hypothesis']['vulnerabilities'][0]['type']
            
            patch_prompt = f"""
다음 취약점에 대한 보안 패치 코드를 생성해주세요:
- 함수: {function_name}
- 취약점 유형: {vuln_type}
- 설명: {vuln['hypothesis']['vulnerabilities'][0]['description']}

패치 코드만 제공해주세요.
"""
            
            response = self.llm.generate_response(patch_prompt)
            
            return {
                "vulnerability_id": f"{vuln['file']}#{function_name}",
                "patch_type": vuln_type,
                "patch_code": response,
                "description": f"LLM 기반 패치 for {vuln_type} in {function_name}",
                "confidence": 0.7,
                "method": "llm_generated"
            }
            
        except Exception as e:
            self.logger.error(f"LLM 패치 생성 실패: {e}")
            return None
    
    def _save_rule(self, rule_type: str, vuln_id: int, func_name: str, rule_content: str):
        """규칙 파일 저장"""
        if not rule_content.strip():
            return None
        
        # 디렉토리가 존재하지 않으면 생성
        self.rule_dir.mkdir(parents=True, exist_ok=True)
            
        rule_file = self.rule_dir / f"{rule_type}{vuln_id}-{func_name}"
        with open(rule_file, 'w', encoding='utf-8') as f:
            f.write(rule_content)
        self.logger.info(f"규칙 저장됨: {rule_file}")
        return rule_file
    
    def _is_vulnerability_confirmed(self, semgrep_results: Dict[str, Any], codeql_results: Dict[str, Any]) -> bool:
        """정적 분석 도구 결과를 바탕으로 취약점 확인"""
        confirmed = False
        confidence_score = 0.0
        
        # Semgrep 결과 확인
        if semgrep_results and semgrep_results.get("status") == "success":
            findings = semgrep_results.get("findings", [])
            if findings:
                confirmed = True
                confidence_score += 0.6  # Semgrep 검증시 60% 신뢰도
                self.logger.info(f"Semgrep 검증 성공: {len(findings)}개 발견")
        
        # CodeQL 결과 확인  
        if codeql_results and codeql_results.get("status") == "success":
            findings = codeql_results.get("findings", [])
            if findings and len(findings) > 1:  # CSV 헤더 제외
                confirmed = True
                confidence_score += 0.4  # CodeQL 검증시 40% 신뢰도
                self.logger.info(f"CodeQL 검증 성공: {len(findings)-1}개 발견")
        
        # 검증 실패 로그
        if not confirmed:
            self.logger.warning("정적 분석 도구 검증 실패 - 취약점 미확인")
            
        return confirmed
    
    def _save_analysis_result(self, result: Dict[str, Any]):
        """분석 결과 저장"""
        # 디렉토리가 존재하지 않으면 생성
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        result_file = self.log_dir / f"analysis_result_{self.vuln_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        self.logger.info(f"분석 결과 저장됨: {result_file}")
    
    def _generate_template_patch(self, vulnerability: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """템플릿 기반 패치 생성"""
        try:
            # 기존 코드 추출
            file_path = f"benchmark/Java/VUL4J/VUL4J-{self.vuln_id}/{vulnerability['file']}"
            existing_code = ""
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    existing_code = f.read()
            
            # 유사도 엔진을 사용한 패치 생성
            template_patch = self.patch_similarity_engine.generate_similarity_based_patch(
                vulnerability, existing_code
            )
            
            if template_patch:
                self.logger.info(f"템플릿 기반 패치 생성: {vulnerability['function']}")
                return template_patch
                
        except Exception as e:
            self.logger.error(f"템플릿 패치 생성 실패: {e}")
        
        return None

    def _iterative_patch_validation(self, vulnerability: Dict[str, Any], 
                                   patch: Dict[str, Any]) -> Dict[str, Any]:
        """반복적 패치 검증 및 개선 - CodeQL 재실행 후 취약점 존재 시 재패치"""
        max_iterations = 10
        current_patch = patch.copy()
        
        for iteration in range(1, max_iterations + 1):
            self.logger.info(f"패치 검증 반복 {iteration}/{max_iterations}")
            
            # 패치 적용
            patched_file_path = self._apply_patch(current_patch)
            if not patched_file_path:
                self.logger.error(f"패치 적용 실패 - 반복 {iteration}")
                break
            
            # 정적 분석 도구로 검증
            validation_result = self._validate_with_static_analysis(vulnerability, patched_file_path)
            
            # CodeQL이 여전히 취약점을 발견한 경우
            if self._is_still_vulnerable(validation_result):
                self.logger.warning(f"패치 후에도 취약점 존재 - 반복 {iteration}")
                self.logger.info("LLM에게 재패치 요청")
                
                # LLM에게 재패치 요청
                improved_patch = self._request_llm_re_patch(vulnerability, current_patch, validation_result, iteration)
                if improved_patch:
                    current_patch = improved_patch
                    self.logger.info(f"LLM 재패치 생성 완료 - 반복 {iteration}")
                else:
                    # LLM 재패치 실패 시 기존 방식으로 개선
                    current_patch = self._improve_patch(current_patch, validation_result, iteration)
            else:
                # 취약점이 해결된 경우
                self.logger.info(f"✅ 패치 검증 성공! (반복 {iteration})")
                current_patch['validation_status'] = 'success'
                current_patch['validation_iterations'] = iteration
                current_patch['final_validation_result'] = validation_result
                self._restore_original_files()
                return current_patch
            
            # 원본 파일 복원 (다음 반복을 위해)
            self._restore_original_files()
            
            # 최대 반복 횟수 도달 시
            if iteration == max_iterations:
                self.logger.error(f"최대 반복 횟수 도달 - 패치 검증 실패")
                current_patch['validation_status'] = 'failed'
                current_patch['validation_iterations'] = iteration
                current_patch['final_validation_result'] = validation_result
                break
        
        return current_patch
    
    def _is_still_vulnerable(self, validation_result: Dict[str, Any]) -> bool:
        """검증 결과에서 여전히 취약점이 존재하는지 확인"""
        # CodeQL 결과 확인
        codeql_findings = validation_result.get('codeql_findings', [])
        if codeql_findings and len(codeql_findings) > 1:  # CSV 헤더 제외
            return True
        
        # Semgrep 결과 확인
        semgrep_findings = validation_result.get('semgrep_findings', [])
        if semgrep_findings:
            return True
        
        return False
    
    def _request_llm_re_patch(self, vulnerability: Dict[str, Any], 
                             current_patch: Dict[str, Any], 
                             validation_result: Dict[str, Any], 
                             iteration: int) -> Optional[Dict[str, Any]]:
        """LLM에게 재패치 요청"""
        try:
            from llm_interfaces import LLMInterface
            
            # LLM 인터페이스가 없으면 스킵
            if not hasattr(self, 'llm') or not self.llm:
                return None
            
            # 재패치 프롬프트 생성
            re_patch_prompt = self._generate_re_patch_prompt(
                vulnerability, current_patch, validation_result, iteration
            )
            
            # LLM 호출
            response = self.llm.generate_response(re_patch_prompt)
            
            if response and len(response.strip()) > 50:
                # 응답에서 패치 코드 추출
                improved_patch = self._parse_llm_re_patch_response(response, current_patch)
                if improved_patch:
                    improved_patch['method'] = f'llm_re_patch_{iteration}'
                    improved_patch['re_patch_iteration'] = iteration
                    return improved_patch
                    
        except Exception as e:
            self.logger.error(f"LLM 재패치 요청 실패: {e}")
        
        return None
    
    def _generate_re_patch_prompt(self, vulnerability: Dict[str, Any], 
                                 current_patch: Dict[str, Any], 
                                 validation_result: Dict[str, Any], 
                                 iteration: int) -> str:
        """재패치를 위한 프롬프트 생성"""
        vuln_type = vulnerability.get('hypothesis', {}).get('vulnerabilities', [{}])[0].get('type', 'Unknown')
        function_name = vulnerability.get('function', 'unknown')
        
        # 검증 실패 원인 분석
        failure_reasons = []
        if validation_result.get('codeql_findings'):
            failure_reasons.append("CodeQL이 여전히 취약점을 탐지함")
        if validation_result.get('semgrep_findings'):
            failure_reasons.append("Semgrep이 여전히 취약점을 탐지함")
        
        prompt = f"""
현재 패치가 취약점을 완전히 해결하지 못했습니다. 더 강력한 패치를 생성해주세요.

**취약점 정보:**
- 함수: {function_name}
- 취약점 유형: {vuln_type}
- 반복 횟수: {iteration}

**현재 패치:**
```java
{current_patch.get('patch_code', '')}
```

**검증 실패 원인:**
{', '.join(failure_reasons)}

**요구사항:**
1. 현재 패치보다 더 강력한 보안 조치 적용
2. 취약점을 완전히 차단하는 코드 작성
3. 반복 {iteration}차이므로 더 엄격한 검증 로직 포함
4. 응답은 반드시 ```java로 시작하는 코드 블록 포함

더 안전하고 강력한 패치를 생성해주세요:
"""
        
        return prompt.strip()
    
    def _parse_llm_re_patch_response(self, response: str, current_patch: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """LLM 재패치 응답 파싱"""
        try:
            # Java 코드 블록 추출
            import re
            java_pattern = r'```java\s*\n(.*?)\n```'
            matches = re.findall(java_pattern, response, re.DOTALL)
            
            if matches:
                new_patch_code = matches[0].strip()
                
                # 새로운 패치 생성
                improved_patch = current_patch.copy()
                improved_patch['patch_code'] = new_patch_code
                improved_patch['description'] = f"LLM 재패치 (개선된 보안 조치)"
                improved_patch['confidence'] = min(0.9, current_patch.get('confidence', 0.5) + 0.1)
                
                return improved_patch
                
        except Exception as e:
            self.logger.error(f"LLM 재패치 응답 파싱 실패: {e}")
        
        return None